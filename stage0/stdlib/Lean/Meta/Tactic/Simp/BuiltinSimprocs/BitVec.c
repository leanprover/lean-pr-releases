// Lean compiler output
// Module: Lean.Meta.Tactic.Simp.BuiltinSimprocs.BitVec
// Imports: Lean.Meta.LitValues Lean.Meta.Tactic.Simp.BuiltinSimprocs.Nat Lean.Meta.Tactic.Simp.BuiltinSimprocs.Int Init.Data.BitVec.Basic
#include <lean/lean.h>
#if defined(__clang__)
#pragma clang diagnostic ignored "-Wunused-parameter"
#pragma clang diagnostic ignored "-Wunused-label"
#elif defined(__GNUC__) && !defined(__CLANG__)
#pragma GCC diagnostic ignored "-Wunused-parameter"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif
#ifdef __cplusplus
extern "C" {
#endif
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2;
lean_object* l_BitVec_abs(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964_(lean_object*);
lean_object* l_Lean_Expr_const___override(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetMsb___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__12;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1189_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__5;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3028_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
lean_object* lean_format_pretty(lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__4;
static lean_object* l_BitVec_reduceGT___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__8;
static lean_object* l_BitVec_reduceSShiftRight___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__10;
static lean_object* l_BitVec_reduceExtracLsb_x27___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14;
lean_object* l_Lean_mkNatLit(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__3;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__9;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2;
static lean_object* l_BitVec_reduceShiftLeft___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2919_(lean_object*);
static lean_object* l_BitVec_reduceLT___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3268_(lean_object*);
static lean_object* l_BitVec_reduceAllOnes___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceNot(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_mk_empty_array_with_capacity(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1749_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2119_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAllOnes___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542_(lean_object*);
static lean_object* l_BitVec_reduceSub___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__3;
lean_object* l_Lean_Meta_getNatValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__4;
static lean_object* l_BitVec_reduceHShiftLeft___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788_(lean_object*);
static lean_object* l_BitVec_reduceHShiftRight___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374_(lean_object*);
lean_object* l_BitVec_replicate(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__10;
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2876_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__5;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1334_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500_(lean_object*);
lean_object* l_Lean_mkAppB(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceNeg___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__1;
static lean_object* l_BitVec_reduceGetLsb___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3752_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__5;
uint8_t l_Lean_Expr_isAppOfArity(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4;
static lean_object* l_BitVec_reduceULE___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1650_(lean_object*);
lean_object* lean_array_push(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__11;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceXOr___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3750_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152_(lean_object*);
static lean_object* l_BitVec_reduceUShiftRight___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__6;
static lean_object* l_BitVec_reduceAppend___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceLE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814_(lean_object*);
static lean_object* l_BitVec_reduceLT___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_(lean_object*);
static lean_object* l_BitVec_reduceBin___lambda__2___closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3792_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__4;
static lean_object* l_BitVec_reduceRotateRight___closed__2;
static lean_object* l_BitVec_reduceUMod___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1(lean_object*, lean_object*, uint8_t, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__1;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__2;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3903_(lean_object*);
static lean_object* l_BitVec_reduceReplicate___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8;
static lean_object* l_BitVec_reduceCast___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1792_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901_(lean_object*);
static lean_object* l_BitVec_reduceOfInt___closed__1;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceNot___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1292_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__3;
lean_object* l_Lean_Meta_Simp_evalPropStep(lean_object*, uint8_t, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBin___lambda__2___closed__14;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__5;
lean_object* l_BitVec_extractLsb_x27___rarg(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
static lean_object* l_BitVec_reduceDiv___closed__3;
lean_object* l_Lean_stringToMessageData(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__3;
static lean_object* l_BitVec_reduceUMod___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceAnd(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1210_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1544_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3051_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__6;
lean_object* l_BitVec_shiftLeft(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__5;
uint8_t lean_int_dec_le(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceAnd___closed__3;
lean_object* lean_nat_shiftr(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2874_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1728_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14;
static lean_object* l_BitVec_reduceSLE___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3095_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__7;
lean_object* l_Lean_Level_ofNat(lean_object*);
lean_object* l_Lean_Expr_appArg_x21(lean_object*);
static lean_object* l_BitVec_reduceAbs___closed__1;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__11;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__1;
lean_object* l_BitVec_smtUDiv(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceMul___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__5;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3005_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3604_(lean_object*);
static lean_object* l_BitVec_reduceSignExtend___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAbs(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_allOnes(lean_object*);
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__4;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__4;
static lean_object* l_BitVec_reduceDiv___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__4;
static lean_object* l_BitVec_reduceHShiftRight___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378_(lean_object*);
static lean_object* l_BitVec_reduceOr___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3771_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3905_(lean_object*);
static lean_object* l_BitVec_reduceULT___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__10;
static lean_object* l_BitVec_reduceExtracLsb_x27___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
extern lean_object* l_Lean_Meta_Simp_builtinSimprocsRef;
lean_object* l_BitVec_neg(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__3;
lean_object* l_Lean_Meta_getIntValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__3;
uint8_t lean_nat_dec_eq(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__7;
static lean_object* l_BitVec_reduceHShiftRight___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBin___lambda__2___closed__9;
LEAN_EXPORT lean_object* l_BitVec_reduceBin(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__5;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__15;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__11;
lean_object* l_BitVec_ofInt(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1208_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1502_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__5;
lean_object* l_BitVec_not(lean_object*, lean_object*);
lean_object* lean_nat_to_int(lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__9;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceULT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_div(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceXOr___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__1;
static lean_object* l_BitVec_reduceSMTSDiv___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3074_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__3;
static lean_object* l_BitVec_reduceDiv___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__1;
static lean_object* l_BitVec_reduceZeroExtend_x27___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred(lean_object*, lean_object*, lean_object*, lean_object*, uint8_t, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__3;
static lean_object* l_BitVec_reduceZeroExtend___closed__2;
static lean_object* l_BitVec_reduceXOr___closed__3;
static lean_object* l_BitVec_reduceGetMsb___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__1;
static lean_object* l_BitVec_reduceShiftLeft___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3072_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_smtSDiv(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__1;
static lean_object* l_BitVec_reduceRotateLeft___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceULE___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1187_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__12;
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2;
static lean_object* l_BitVec_reduceGT___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8;
lean_object* l_Lean_Meta_getBitVecValue_x3f(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_ofNat(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2;
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3773_(lean_object*);
static lean_object* l_BitVec_reduceMul___closed__2;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__3;
static lean_object* l_BitVec_reduceLT___closed__2;
static lean_object* l_BitVec_reduceToInt___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSDiv___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNeg(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1726_(lean_object*);
static lean_object* l_BitVec_reduceBin___lambda__2___closed__13;
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1418_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3416_(lean_object*);
static lean_object* l_BitVec_reduceSignExtend___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGE___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252_(lean_object*);
lean_object* l_BitVec_srem(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2833_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1790_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_BitVec_sdiv(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1674_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__7;
static lean_object* l_BitVec_reduceAppend___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938_(lean_object*);
static lean_object* l_BitVec_reduceUShiftRight___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1700_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__13;
lean_object* l_BitVec_add(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3049_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__14;
LEAN_EXPORT lean_object* l_BitVec_reduceMul(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_land(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2635_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2270_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__4;
static lean_object* l_BitVec_reduceAnd___closed__2;
lean_object* l_Lean_Name_str___override(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceSub(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToNat___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__5;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__1;
static lean_object* l_BitVec_reduceGT___closed__2;
lean_object* l_BitVec_zeroExtend(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12;
static lean_object* l_BitVec_reduceMul___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceUnary(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2;
static lean_object* l_BitVec_reduceSub___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2633_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__5;
static lean_object* l_BitVec_reduceLE___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__3;
static lean_object* l_BitVec_reduceSMTUDiv___closed__2;
static lean_object* l_BitVec_reduceZeroExtend_x27___closed__1;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__4;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8;
static lean_object* l_BitVec_reduceAppend___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2484_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__8;
static lean_object* l_BitVec_reduceCast___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2378_(lean_object*);
lean_object* l_Lean_Expr_appFn_x21(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12;
static lean_object* l_BitVec_reduceLE___closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248_(lean_object*);
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__4;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3794_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOfInt___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__1;
extern lean_object* l_Std_Format_defWidth;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__7;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__4;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2;
lean_object* l_BitVec_sshiftRight(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceGT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2;
static lean_object* l_BitVec_reduceSLE___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__4;
uint8_t l_BitVec_slt(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceMod___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8;
static lean_object* l_BitVec_reduceSRem___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__5;
static lean_object* l_BitVec_reduceNot___closed__3;
static lean_object* l_BitVec_reduceAbs___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__8;
static lean_object* l_BitVec_reduceOr___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1570_(lean_object*);
lean_object* l_BitVec_append___rarg(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceCast(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1376_(lean_object*);
lean_object* l_BitVec_rotateRight(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1940_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2960_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__6;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__13;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8;
static lean_object* l_BitVec_reduceMod___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14;
static lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__12;
static lean_object* l_BitVec_reduceReplicate___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__10;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__7;
lean_object* lean_nat_lxor(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__6;
uint8_t l_Nat_testBit(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__8;
static lean_object* l_BitVec_reduceNot___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceToInt___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__6;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2;
static lean_object* l_BitVec_reduceAnd___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10;
static lean_object* l_BitVec_reduceAdd___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUDiv___closed__1;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__6;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__3;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__12;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294_(lean_object*);
lean_object* l_BitVec_signExtend(lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_Meta_Simp_registerBuiltinSimproc(lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1622_(lean_object*);
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__11;
static lean_object* l_BitVec_reduceHShiftLeft___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__5;
uint8_t lean_nat_dec_eq(lean_object*, lean_object*);
static lean_object* l_BitVec_reduceOr___closed__2;
lean_object* l_Lean_mkApp3(lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__7;
static lean_object* l_BitVec_reduceLE___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__7;
uint8_t lean_nat_dec_lt(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__10;
static lean_object* l_BitVec_reduceNeg___closed__3;
lean_object* lean_nat_mod(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__11;
static lean_object* l_BitVec_reduceAdd___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__12;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3418_(lean_object*);
static lean_object* l_BitVec_reduceSRem___closed__1;
lean_object* l_Lean_Name_mkStr2(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__7;
lean_object* l_BitVec_rotateLeft(lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(lean_object*, lean_object*, uint8_t, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__8;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__5;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__4;
static lean_object* l_BitVec_reduceUDiv___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3026_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShift(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__8;
static lean_object* l_BitVec_reduceNeg___closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__5;
static lean_object* l_BitVec_reduceToNat___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__7;
lean_object* l_BitVec_toInt(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__4;
lean_object* l_Int_toNat(lean_object*);
static lean_object* l_BitVec_reduceSShiftRight___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__9;
static lean_object* l_BitVec_reduceBin___lambda__2___closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__1;
lean_object* lean_nat_shiftl(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceMod(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBin___lambda__2___closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceXOr(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1768_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
lean_object* lean_nat_sub(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1942_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__10;
lean_object* lean_nat_mul(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceExtend(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__5;
static lean_object* l_BitVec_reduceSub___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1624_(lean_object*);
static lean_object* l_BitVec_reduceBin___lambda__2___closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSRem(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSLT___closed__2;
static lean_object* l_BitVec_reduceSMod___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2917_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12;
static lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__10;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2962_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceOr(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceULT___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__7;
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__1;
lean_object* l_BitVec_smod(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__6;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2831_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSLE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGE___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1702_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__4;
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__5;
static lean_object* l_BitVec_reduceSMTSDiv___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2;
lean_object* l_BitVec_mul(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceGE___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
static lean_object* l_BitVec_reduceMod___closed__3;
static lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__12;
static lean_object* l_BitVec_reduceToInt___lambda__1___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2;
lean_object* l_Lean_instToExprInt_mkNat(lean_object*);
static lean_object* l_BitVec_reduceRotateRight___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__13;
static lean_object* l_BitVec_reduceZeroExtend___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__5;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3270_(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceShiftLeftZeroExtend___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__7;
static lean_object* l_BitVec_reduceRotateLeft___closed__2;
LEAN_EXPORT lean_object* l_BitVec_reduceSLT(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1648_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__1;
static lean_object* l_BitVec_reduceAdd___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2268_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__3;
lean_object* l_BitVec_toHex(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceHShiftLeft___closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__6;
static lean_object* l_BitVec_reduceSLT___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3097_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2121_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__1;
static lean_object* l_BitVec_reduceSMod___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1747_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3003_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__4;
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8;
lean_object* lean_int_neg(lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
extern lean_object* l_Lean_Meta_Simp_builtinSEvalprocsRef;
uint8_t lean_nat_dec_le(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__6;
static lean_object* l_BitVec_reduceGetBit___lambda__1___closed__4;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__1;
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__5;
lean_object* lean_nat_add(lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__9;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2376_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__3;
static lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8;
static lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__6;
static lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__11;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__6;
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1250_(lean_object*);
static lean_object* l_BitVec_reduceGetLsb___closed__1;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3602_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594_(lean_object*);
lean_object* l_Lean_MessageData_ofName(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__1;
static lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8;
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceBin___lambda__2___closed__5;
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8;
lean_object* lean_nat_lor(lean_object*, lean_object*);
LEAN_EXPORT lean_object* l_BitVec_reduceULE(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceSDiv___closed__2;
static lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2;
static lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__4;
lean_object* l_Nat_repr(lean_object*);
lean_object* l_BitVec_sub(lean_object*, lean_object*, lean_object*);
static lean_object* l_BitVec_reduceUnary___lambda__1___closed__2;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2486_(lean_object*);
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1460_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__3;
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___boxed(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__13;
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__2(lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*, lean_object*);
uint8_t l_BitVec_sle(lean_object*, lean_object*, lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__5;
static lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__10;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__7;
static lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__3;
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1572_(lean_object*);
static lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__4;
static lean_object* l_BitVec_reduceSMTUDiv___closed__1;
static lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__4;
static lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__5;
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_Lean_Meta_getBitVecValue_x3f(x_1, x_5, x_6, x_7, x_8, x_9);
if (lean_obj_tag(x_10) == 0)
{
lean_object* x_11; 
x_11 = lean_ctor_get(x_10, 0);
lean_inc(x_11);
if (lean_obj_tag(x_11) == 0)
{
uint8_t x_12; 
x_12 = !lean_is_exclusive(x_10);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
x_13 = lean_ctor_get(x_10, 0);
lean_dec(x_13);
x_14 = lean_box(0);
lean_ctor_set(x_10, 0, x_14);
return x_10;
}
else
{
lean_object* x_15; lean_object* x_16; lean_object* x_17; 
x_15 = lean_ctor_get(x_10, 1);
lean_inc(x_15);
lean_dec(x_10);
x_16 = lean_box(0);
x_17 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_17, 0, x_16);
lean_ctor_set(x_17, 1, x_15);
return x_17;
}
}
else
{
uint8_t x_18; 
x_18 = !lean_is_exclusive(x_11);
if (x_18 == 0)
{
uint8_t x_19; 
x_19 = !lean_is_exclusive(x_10);
if (x_19 == 0)
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_20 = lean_ctor_get(x_11, 0);
x_21 = lean_ctor_get(x_10, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_20, 0);
lean_inc(x_22);
x_23 = lean_ctor_get(x_20, 1);
lean_inc(x_23);
lean_dec(x_20);
x_24 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_24, 0, x_22);
lean_ctor_set(x_24, 1, x_23);
lean_ctor_set(x_11, 0, x_24);
return x_10;
}
else
{
lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; 
x_25 = lean_ctor_get(x_11, 0);
x_26 = lean_ctor_get(x_10, 1);
lean_inc(x_26);
lean_dec(x_10);
x_27 = lean_ctor_get(x_25, 0);
lean_inc(x_27);
x_28 = lean_ctor_get(x_25, 1);
lean_inc(x_28);
lean_dec(x_25);
x_29 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_29, 0, x_27);
lean_ctor_set(x_29, 1, x_28);
lean_ctor_set(x_11, 0, x_29);
x_30 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_30, 0, x_11);
lean_ctor_set(x_30, 1, x_26);
return x_30;
}
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; 
x_31 = lean_ctor_get(x_11, 0);
lean_inc(x_31);
lean_dec(x_11);
x_32 = lean_ctor_get(x_10, 1);
lean_inc(x_32);
if (lean_is_exclusive(x_10)) {
 lean_ctor_release(x_10, 0);
 lean_ctor_release(x_10, 1);
 x_33 = x_10;
} else {
 lean_dec_ref(x_10);
 x_33 = lean_box(0);
}
x_34 = lean_ctor_get(x_31, 0);
lean_inc(x_34);
x_35 = lean_ctor_get(x_31, 1);
lean_inc(x_35);
lean_dec(x_31);
x_36 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_36, 0, x_34);
lean_ctor_set(x_36, 1, x_35);
x_37 = lean_alloc_ctor(1, 1, 0);
lean_ctor_set(x_37, 0, x_36);
if (lean_is_scalar(x_33)) {
 x_38 = lean_alloc_ctor(0, 2, 0);
} else {
 x_38 = x_33;
}
lean_ctor_set(x_38, 0, x_37);
lean_ctor_set(x_38, 1, x_32);
return x_38;
}
}
}
else
{
uint8_t x_39; 
x_39 = !lean_is_exclusive(x_10);
if (x_39 == 0)
{
return x_10;
}
else
{
lean_object* x_40; lean_object* x_41; lean_object* x_42; 
x_40 = lean_ctor_get(x_10, 0);
x_41 = lean_ctor_get(x_10, 1);
lean_inc(x_41);
lean_inc(x_40);
lean_dec(x_10);
x_42 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_42, 0, x_40);
lean_ctor_set(x_42, 1, x_41);
return x_42;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_fromExpr_x3f___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_fromExpr_x3f(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_box(0);
x_2 = lean_alloc_ctor(2, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("BitVec", 6);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__3() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ofNat", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUnary___lambda__1___closed__3;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceUnary___lambda__1___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceUnary___lambda__1___closed__4;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_2);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
uint8_t x_21; 
x_21 = !lean_is_exclusive(x_13);
if (x_21 == 0)
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; lean_object* x_31; uint32_t x_32; uint8_t x_33; lean_object* x_34; lean_object* x_35; 
x_22 = lean_ctor_get(x_13, 0);
lean_dec(x_22);
x_23 = lean_ctor_get(x_14, 0);
lean_inc(x_23);
lean_dec(x_14);
x_24 = lean_ctor_get(x_23, 0);
lean_inc(x_24);
x_25 = lean_ctor_get(x_23, 1);
lean_inc(x_25);
lean_dec(x_23);
lean_inc(x_24);
x_26 = lean_apply_2(x_2, x_24, x_25);
x_27 = l_Lean_mkNatLit(x_24);
x_28 = l_Lean_mkNatLit(x_26);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_30 = l_Lean_mkAppB(x_29, x_27, x_28);
x_31 = lean_box(0);
x_32 = 0;
x_33 = 1;
x_34 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_34, 0, x_30);
lean_ctor_set(x_34, 1, x_31);
lean_ctor_set_uint32(x_34, sizeof(void*)*2, x_32);
lean_ctor_set_uint8(x_34, sizeof(void*)*2 + 4, x_33);
x_35 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_35, 0, x_34);
lean_ctor_set(x_13, 0, x_35);
return x_13;
}
else
{
lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; uint32_t x_46; uint8_t x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_36 = lean_ctor_get(x_13, 1);
lean_inc(x_36);
lean_dec(x_13);
x_37 = lean_ctor_get(x_14, 0);
lean_inc(x_37);
lean_dec(x_14);
x_38 = lean_ctor_get(x_37, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_37, 1);
lean_inc(x_39);
lean_dec(x_37);
lean_inc(x_38);
x_40 = lean_apply_2(x_2, x_38, x_39);
x_41 = l_Lean_mkNatLit(x_38);
x_42 = l_Lean_mkNatLit(x_40);
x_43 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_44 = l_Lean_mkAppB(x_43, x_41, x_42);
x_45 = lean_box(0);
x_46 = 0;
x_47 = 1;
x_48 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_48, 0, x_44);
lean_ctor_set(x_48, 1, x_45);
lean_ctor_set_uint32(x_48, sizeof(void*)*2, x_46);
lean_ctor_set_uint8(x_48, sizeof(void*)*2 + 4, x_47);
x_49 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_49, 0, x_48);
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_36);
return x_50;
}
}
}
else
{
uint8_t x_51; 
lean_dec(x_2);
x_51 = !lean_is_exclusive(x_13);
if (x_51 == 0)
{
return x_13;
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_52 = lean_ctor_get(x_13, 0);
x_53 = lean_ctor_get(x_13, 1);
lean_inc(x_53);
lean_inc(x_52);
lean_dec(x_13);
x_54 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_54, 0, x_52);
lean_ctor_set(x_54, 1, x_53);
return x_54;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceUnary___lambda__1(x_4, x_3, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUnary___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceUnary___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12, lean_object* x_13) {
_start:
{
lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; lean_object* x_21; uint32_t x_22; uint8_t x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_14 = lean_ctor_get(x_1, 1);
lean_inc(x_14);
lean_dec(x_1);
x_15 = lean_ctor_get(x_2, 1);
lean_inc(x_15);
lean_dec(x_2);
lean_inc(x_4);
x_16 = lean_apply_3(x_3, x_4, x_14, x_15);
x_17 = l_Lean_mkNatLit(x_4);
x_18 = l_Lean_mkNatLit(x_16);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_20 = l_Lean_mkAppB(x_19, x_17, x_18);
x_21 = lean_box(0);
x_22 = 0;
x_23 = 1;
x_24 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_24, 0, x_20);
lean_ctor_set(x_24, 1, x_21);
lean_ctor_set_uint32(x_24, sizeof(void*)*2, x_22);
lean_ctor_set_uint8(x_24, sizeof(void*)*2 + 4, x_23);
x_25 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_25, 0, x_24);
x_26 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_26, 0, x_25);
lean_ctor_set(x_26, 1, x_13);
return x_26;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Meta", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("debug", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceBin___lambda__2___closed__1;
x_2 = l_BitVec_reduceBin___lambda__2___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__4() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduce [", 8);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBin___lambda__2___closed__4;
x_2 = l_Lean_stringToMessageData(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__6() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("] ", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBin___lambda__2___closed__6;
x_2 = l_Lean_stringToMessageData(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("0x", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBin___lambda__2___closed__8;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__10() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("#", 1);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBin___lambda__2___closed__10;
x_2 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes(", ", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBin___lambda__2___closed__12;
x_2 = l_Lean_stringToMessageData(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("", 0);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceBin___lambda__2___closed__15() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceBin___lambda__2___closed__14;
x_2 = l_Lean_stringToMessageData(x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; 
lean_dec(x_4);
lean_inc(x_1);
x_13 = l_Lean_Expr_appFn_x21(x_1);
x_14 = l_Lean_Expr_appArg_x21(x_13);
lean_dec(x_13);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_15 = l_BitVec_fromExpr_x3f(x_14, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_14);
if (lean_obj_tag(x_15) == 0)
{
lean_object* x_16; 
x_16 = lean_ctor_get(x_15, 0);
lean_inc(x_16);
if (lean_obj_tag(x_16) == 0)
{
uint8_t x_17; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_17 = !lean_is_exclusive(x_15);
if (x_17 == 0)
{
lean_object* x_18; lean_object* x_19; 
x_18 = lean_ctor_get(x_15, 0);
lean_dec(x_18);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_15, 0, x_19);
return x_15;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_15, 1);
lean_inc(x_20);
lean_dec(x_15);
x_21 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_21);
lean_ctor_set(x_22, 1, x_20);
return x_22;
}
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_23 = lean_ctor_get(x_15, 1);
lean_inc(x_23);
lean_dec(x_15);
x_24 = lean_ctor_get(x_16, 0);
lean_inc(x_24);
lean_dec(x_16);
x_25 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_26 = l_BitVec_fromExpr_x3f(x_25, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_23);
lean_dec(x_25);
if (lean_obj_tag(x_26) == 0)
{
lean_object* x_27; 
x_27 = lean_ctor_get(x_26, 0);
lean_inc(x_27);
if (lean_obj_tag(x_27) == 0)
{
uint8_t x_28; 
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
lean_dec(x_2);
x_28 = !lean_is_exclusive(x_26);
if (x_28 == 0)
{
lean_object* x_29; lean_object* x_30; 
x_29 = lean_ctor_get(x_26, 0);
lean_dec(x_29);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_26, 0, x_30);
return x_26;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_26, 1);
lean_inc(x_31);
lean_dec(x_26);
x_32 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_33 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_33, 0, x_32);
lean_ctor_set(x_33, 1, x_31);
return x_33;
}
}
else
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_26);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; uint8_t x_40; 
x_35 = lean_ctor_get(x_26, 1);
x_36 = lean_ctor_get(x_26, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_27, 0);
lean_inc(x_37);
lean_dec(x_27);
x_38 = lean_ctor_get(x_24, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_37, 0);
lean_inc(x_39);
x_40 = lean_nat_dec_eq(x_38, x_39);
if (x_40 == 0)
{
lean_object* x_41; 
lean_dec(x_39);
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
lean_dec(x_2);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_26, 0, x_41);
return x_26;
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; uint8_t x_45; 
lean_free_object(x_26);
x_42 = l_BitVec_reduceBin___lambda__2___closed__3;
x_43 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_42, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_35);
x_44 = lean_ctor_get(x_43, 0);
lean_inc(x_44);
x_45 = lean_unbox(x_44);
lean_dec(x_44);
if (x_45 == 0)
{
lean_object* x_46; lean_object* x_47; lean_object* x_48; 
lean_dec(x_39);
lean_dec(x_3);
x_46 = lean_ctor_get(x_43, 1);
lean_inc(x_46);
lean_dec(x_43);
x_47 = lean_box(0);
x_48 = l_BitVec_reduceBin___lambda__1(x_24, x_37, x_2, x_38, x_47, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_46);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_48;
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; lean_object* x_90; 
x_49 = lean_ctor_get(x_43, 1);
lean_inc(x_49);
lean_dec(x_43);
x_50 = l_Lean_MessageData_ofName(x_3);
x_51 = l_BitVec_reduceBin___lambda__2___closed__5;
x_52 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_52, 0, x_51);
lean_ctor_set(x_52, 1, x_50);
x_53 = l_BitVec_reduceBin___lambda__2___closed__7;
x_54 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_54, 0, x_52);
lean_ctor_set(x_54, 1, x_53);
x_55 = lean_ctor_get(x_24, 1);
lean_inc(x_55);
x_56 = l_BitVec_toHex(x_38, x_55);
x_57 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_57, 0, x_56);
x_58 = l_BitVec_reduceBin___lambda__2___closed__9;
x_59 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_59, 0, x_58);
lean_ctor_set(x_59, 1, x_57);
x_60 = l_BitVec_reduceBin___lambda__2___closed__11;
x_61 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
lean_inc(x_38);
x_62 = l_Nat_repr(x_38);
x_63 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_64, 0, x_61);
lean_ctor_set(x_64, 1, x_63);
x_65 = l_Std_Format_defWidth;
x_66 = lean_unsigned_to_nat(0u);
x_67 = lean_format_pretty(x_64, x_65, x_66, x_66);
x_68 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_69, 0, x_68);
x_70 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_70, 0, x_54);
lean_ctor_set(x_70, 1, x_69);
x_71 = l_BitVec_reduceBin___lambda__2___closed__13;
x_72 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
x_73 = lean_ctor_get(x_37, 1);
lean_inc(x_73);
x_74 = l_BitVec_toHex(x_39, x_73);
x_75 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_75, 0, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_58);
lean_ctor_set(x_76, 1, x_75);
x_77 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_77, 0, x_76);
lean_ctor_set(x_77, 1, x_60);
x_78 = l_Nat_repr(x_39);
x_79 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_79, 0, x_78);
x_80 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_80, 0, x_77);
lean_ctor_set(x_80, 1, x_79);
x_81 = lean_format_pretty(x_80, x_65, x_66, x_66);
x_82 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_83, 0, x_82);
x_84 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_84, 0, x_72);
lean_ctor_set(x_84, 1, x_83);
x_85 = l_BitVec_reduceBin___lambda__2___closed__15;
x_86 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_86, 0, x_84);
lean_ctor_set(x_86, 1, x_85);
x_87 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_42, x_86, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_49);
x_88 = lean_ctor_get(x_87, 0);
lean_inc(x_88);
x_89 = lean_ctor_get(x_87, 1);
lean_inc(x_89);
lean_dec(x_87);
x_90 = l_BitVec_reduceBin___lambda__1(x_24, x_37, x_2, x_38, x_88, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_89);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_88);
return x_90;
}
}
}
else
{
lean_object* x_91; lean_object* x_92; lean_object* x_93; lean_object* x_94; uint8_t x_95; 
x_91 = lean_ctor_get(x_26, 1);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_27, 0);
lean_inc(x_92);
lean_dec(x_27);
x_93 = lean_ctor_get(x_24, 0);
lean_inc(x_93);
x_94 = lean_ctor_get(x_92, 0);
lean_inc(x_94);
x_95 = lean_nat_dec_eq(x_93, x_94);
if (x_95 == 0)
{
lean_object* x_96; lean_object* x_97; 
lean_dec(x_94);
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
lean_dec(x_2);
x_96 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_97 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_97, 0, x_96);
lean_ctor_set(x_97, 1, x_91);
return x_97;
}
else
{
lean_object* x_98; lean_object* x_99; lean_object* x_100; uint8_t x_101; 
x_98 = l_BitVec_reduceBin___lambda__2___closed__3;
x_99 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_98, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_91);
x_100 = lean_ctor_get(x_99, 0);
lean_inc(x_100);
x_101 = lean_unbox(x_100);
lean_dec(x_100);
if (x_101 == 0)
{
lean_object* x_102; lean_object* x_103; lean_object* x_104; 
lean_dec(x_94);
lean_dec(x_3);
x_102 = lean_ctor_get(x_99, 1);
lean_inc(x_102);
lean_dec(x_99);
x_103 = lean_box(0);
x_104 = l_BitVec_reduceBin___lambda__1(x_24, x_92, x_2, x_93, x_103, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_102);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_104;
}
else
{
lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; lean_object* x_146; 
x_105 = lean_ctor_get(x_99, 1);
lean_inc(x_105);
lean_dec(x_99);
x_106 = l_Lean_MessageData_ofName(x_3);
x_107 = l_BitVec_reduceBin___lambda__2___closed__5;
x_108 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_108, 0, x_107);
lean_ctor_set(x_108, 1, x_106);
x_109 = l_BitVec_reduceBin___lambda__2___closed__7;
x_110 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_110, 0, x_108);
lean_ctor_set(x_110, 1, x_109);
x_111 = lean_ctor_get(x_24, 1);
lean_inc(x_111);
x_112 = l_BitVec_toHex(x_93, x_111);
x_113 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_113, 0, x_112);
x_114 = l_BitVec_reduceBin___lambda__2___closed__9;
x_115 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_115, 0, x_114);
lean_ctor_set(x_115, 1, x_113);
x_116 = l_BitVec_reduceBin___lambda__2___closed__11;
x_117 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_117, 0, x_115);
lean_ctor_set(x_117, 1, x_116);
lean_inc(x_93);
x_118 = l_Nat_repr(x_93);
x_119 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_119, 0, x_118);
x_120 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_120, 0, x_117);
lean_ctor_set(x_120, 1, x_119);
x_121 = l_Std_Format_defWidth;
x_122 = lean_unsigned_to_nat(0u);
x_123 = lean_format_pretty(x_120, x_121, x_122, x_122);
x_124 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_125, 0, x_124);
x_126 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_126, 0, x_110);
lean_ctor_set(x_126, 1, x_125);
x_127 = l_BitVec_reduceBin___lambda__2___closed__13;
x_128 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_128, 0, x_126);
lean_ctor_set(x_128, 1, x_127);
x_129 = lean_ctor_get(x_92, 1);
lean_inc(x_129);
x_130 = l_BitVec_toHex(x_94, x_129);
x_131 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_131, 0, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_114);
lean_ctor_set(x_132, 1, x_131);
x_133 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_133, 0, x_132);
lean_ctor_set(x_133, 1, x_116);
x_134 = l_Nat_repr(x_94);
x_135 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_135, 0, x_134);
x_136 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_136, 0, x_133);
lean_ctor_set(x_136, 1, x_135);
x_137 = lean_format_pretty(x_136, x_121, x_122, x_122);
x_138 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_139, 0, x_138);
x_140 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_140, 0, x_128);
lean_ctor_set(x_140, 1, x_139);
x_141 = l_BitVec_reduceBin___lambda__2___closed__15;
x_142 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_142, 0, x_140);
lean_ctor_set(x_142, 1, x_141);
x_143 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_98, x_142, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_105);
x_144 = lean_ctor_get(x_143, 0);
lean_inc(x_144);
x_145 = lean_ctor_get(x_143, 1);
lean_inc(x_145);
lean_dec(x_143);
x_146 = l_BitVec_reduceBin___lambda__1(x_24, x_92, x_2, x_93, x_144, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_145);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_144);
return x_146;
}
}
}
}
}
else
{
uint8_t x_147; 
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
lean_dec(x_2);
x_147 = !lean_is_exclusive(x_26);
if (x_147 == 0)
{
return x_26;
}
else
{
lean_object* x_148; lean_object* x_149; lean_object* x_150; 
x_148 = lean_ctor_get(x_26, 0);
x_149 = lean_ctor_get(x_26, 1);
lean_inc(x_149);
lean_inc(x_148);
lean_dec(x_26);
x_150 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_150, 0, x_148);
lean_ctor_set(x_150, 1, x_149);
return x_150;
}
}
}
}
else
{
uint8_t x_151; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_151 = !lean_is_exclusive(x_15);
if (x_151 == 0)
{
return x_15;
}
else
{
lean_object* x_152; lean_object* x_153; lean_object* x_154; 
x_152 = lean_ctor_get(x_15, 0);
x_153 = lean_ctor_get(x_15, 1);
lean_inc(x_153);
lean_inc(x_152);
lean_dec(x_15);
x_154 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_154, 0, x_152);
lean_ctor_set(x_154, 1, x_153);
return x_154;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceBin___lambda__2(x_4, x_3, x_1, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBin___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12, lean_object* x_13) {
_start:
{
lean_object* x_14; 
x_14 = l_BitVec_reduceBin___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13);
lean_dec(x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_14;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; 
x_12 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appFn_x21(x_1);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_7, x_8, x_9, x_10, x_21);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_22);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; uint32_t x_44; uint8_t x_45; lean_object* x_46; lean_object* x_47; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_22, 1);
lean_inc(x_37);
lean_dec(x_22);
lean_inc(x_35);
x_38 = lean_apply_3(x_2, x_36, x_35, x_37);
x_39 = l_Lean_mkNatLit(x_35);
x_40 = l_Lean_mkNatLit(x_38);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_42 = l_Lean_mkAppB(x_41, x_39, x_40);
x_43 = lean_box(0);
x_44 = 0;
x_45 = 1;
x_46 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_46, 0, x_42);
lean_ctor_set(x_46, 1, x_43);
lean_ctor_set_uint32(x_46, sizeof(void*)*2, x_44);
lean_ctor_set_uint8(x_46, sizeof(void*)*2 + 4, x_45);
x_47 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_47, 0, x_46);
lean_ctor_set(x_25, 0, x_47);
return x_25;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; uint32_t x_58; uint8_t x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_48 = lean_ctor_get(x_25, 1);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_26, 0);
lean_inc(x_49);
lean_dec(x_26);
x_50 = lean_ctor_get(x_22, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
lean_inc(x_49);
x_52 = lean_apply_3(x_2, x_50, x_49, x_51);
x_53 = l_Lean_mkNatLit(x_49);
x_54 = l_Lean_mkNatLit(x_52);
x_55 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_56 = l_Lean_mkAppB(x_55, x_53, x_54);
x_57 = lean_box(0);
x_58 = 0;
x_59 = 1;
x_60 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_60, 0, x_56);
lean_ctor_set(x_60, 1, x_57);
lean_ctor_set_uint32(x_60, sizeof(void*)*2, x_58);
lean_ctor_set_uint8(x_60, sizeof(void*)*2 + 4, x_59);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_48);
return x_62;
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_22);
lean_dec(x_2);
x_63 = !lean_is_exclusive(x_25);
if (x_63 == 0)
{
return x_25;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_25, 0);
x_65 = lean_ctor_get(x_25, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_25);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_13);
if (x_67 == 0)
{
return x_13;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_13, 0);
x_69 = lean_ctor_get(x_13, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_13);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; uint8_t x_13; 
x_12 = lean_unsigned_to_nat(3u);
x_13 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_12);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_3);
lean_dec(x_2);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_11);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceExtend___lambda__1(x_3, x_2, x_16, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtend___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceExtend(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_12;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Bool", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("false", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__1;
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__3;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__5() {
_start:
{
lean_object* x_1; uint32_t x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; 
x_1 = lean_box(0);
x_2 = 0;
x_3 = l_BitVec_reduceGetBit___lambda__1___closed__4;
x_4 = 1;
x_5 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_5, 0, x_3);
lean_ctor_set(x_5, 1, x_1);
lean_ctor_set_uint32(x_5, sizeof(void*)*2, x_2);
lean_ctor_set_uint8(x_5, sizeof(void*)*2 + 4, x_4);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__5;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("true", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__1;
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__7;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceGetBit___lambda__1___closed__8;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__10() {
_start:
{
lean_object* x_1; uint32_t x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; 
x_1 = lean_box(0);
x_2 = 0;
x_3 = l_BitVec_reduceGetBit___lambda__1___closed__9;
x_4 = 1;
x_5 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_5, 0, x_3);
lean_ctor_set(x_5, 1, x_1);
lean_ctor_set_uint32(x_5, sizeof(void*)*2, x_2);
lean_ctor_set_uint8(x_5, sizeof(void*)*2 + 4, x_4);
return x_5;
}
}
static lean_object* _init_l_BitVec_reduceGetBit___lambda__1___closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = l_BitVec_reduceGetBit___lambda__1___closed__10;
x_2 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_2, 0, x_1);
return x_2;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_7, x_8, x_9, x_10, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_23, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_23, 1);
lean_inc(x_37);
lean_dec(x_23);
x_38 = lean_apply_3(x_2, x_36, x_37, x_35);
x_39 = lean_unbox(x_38);
lean_dec(x_38);
if (x_39 == 0)
{
lean_object* x_40; 
x_40 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; 
x_41 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_25, 0, x_41);
return x_25;
}
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; lean_object* x_46; uint8_t x_47; 
x_42 = lean_ctor_get(x_25, 1);
lean_inc(x_42);
lean_dec(x_25);
x_43 = lean_ctor_get(x_26, 0);
lean_inc(x_43);
lean_dec(x_26);
x_44 = lean_ctor_get(x_23, 0);
lean_inc(x_44);
x_45 = lean_ctor_get(x_23, 1);
lean_inc(x_45);
lean_dec(x_23);
x_46 = lean_apply_3(x_2, x_44, x_45, x_43);
x_47 = lean_unbox(x_46);
lean_dec(x_46);
if (x_47 == 0)
{
lean_object* x_48; lean_object* x_49; 
x_48 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_49 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_49, 0, x_48);
lean_ctor_set(x_49, 1, x_42);
return x_49;
}
else
{
lean_object* x_50; lean_object* x_51; 
x_50 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_51 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_42);
return x_51;
}
}
}
}
else
{
uint8_t x_52; 
lean_dec(x_23);
lean_dec(x_2);
x_52 = !lean_is_exclusive(x_25);
if (x_52 == 0)
{
return x_25;
}
else
{
lean_object* x_53; lean_object* x_54; lean_object* x_55; 
x_53 = lean_ctor_get(x_25, 0);
x_54 = lean_ctor_get(x_25, 1);
lean_inc(x_54);
lean_inc(x_53);
lean_dec(x_25);
x_55 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_55, 0, x_53);
lean_ctor_set(x_55, 1, x_54);
return x_55;
}
}
}
}
else
{
uint8_t x_56; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_56 = !lean_is_exclusive(x_14);
if (x_56 == 0)
{
return x_14;
}
else
{
lean_object* x_57; lean_object* x_58; lean_object* x_59; 
x_57 = lean_ctor_get(x_14, 0);
x_58 = lean_ctor_get(x_14, 1);
lean_inc(x_58);
lean_inc(x_57);
lean_dec(x_14);
x_59 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_59, 0, x_57);
lean_ctor_set(x_59, 1, x_58);
return x_59;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; uint8_t x_13; 
x_12 = lean_unsigned_to_nat(3u);
x_13 = l_Lean_Expr_isAppOfArity(x_3, x_1, x_12);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_3);
lean_dec(x_2);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_11);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceGetBit___lambda__1(x_3, x_2, x_16, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceGetBit___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetBit___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceGetBit(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_7, x_8, x_9, x_10, x_22);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; uint32_t x_44; uint8_t x_45; lean_object* x_46; lean_object* x_47; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_23, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_23, 1);
lean_inc(x_37);
lean_dec(x_23);
lean_inc(x_36);
x_38 = lean_apply_3(x_2, x_36, x_37, x_35);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkNatLit(x_38);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_42 = l_Lean_mkAppB(x_41, x_39, x_40);
x_43 = lean_box(0);
x_44 = 0;
x_45 = 1;
x_46 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_46, 0, x_42);
lean_ctor_set(x_46, 1, x_43);
lean_ctor_set_uint32(x_46, sizeof(void*)*2, x_44);
lean_ctor_set_uint8(x_46, sizeof(void*)*2 + 4, x_45);
x_47 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_47, 0, x_46);
lean_ctor_set(x_25, 0, x_47);
return x_25;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; uint32_t x_58; uint8_t x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_48 = lean_ctor_get(x_25, 1);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_26, 0);
lean_inc(x_49);
lean_dec(x_26);
x_50 = lean_ctor_get(x_23, 0);
lean_inc(x_50);
x_51 = lean_ctor_get(x_23, 1);
lean_inc(x_51);
lean_dec(x_23);
lean_inc(x_50);
x_52 = lean_apply_3(x_2, x_50, x_51, x_49);
x_53 = l_Lean_mkNatLit(x_50);
x_54 = l_Lean_mkNatLit(x_52);
x_55 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_56 = l_Lean_mkAppB(x_55, x_53, x_54);
x_57 = lean_box(0);
x_58 = 0;
x_59 = 1;
x_60 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_60, 0, x_56);
lean_ctor_set(x_60, 1, x_57);
lean_ctor_set_uint32(x_60, sizeof(void*)*2, x_58);
lean_ctor_set_uint8(x_60, sizeof(void*)*2 + 4, x_59);
x_61 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_61, 0, x_60);
x_62 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_62, 0, x_61);
lean_ctor_set(x_62, 1, x_48);
return x_62;
}
}
}
else
{
uint8_t x_63; 
lean_dec(x_23);
lean_dec(x_2);
x_63 = !lean_is_exclusive(x_25);
if (x_63 == 0)
{
return x_25;
}
else
{
lean_object* x_64; lean_object* x_65; lean_object* x_66; 
x_64 = lean_ctor_get(x_25, 0);
x_65 = lean_ctor_get(x_25, 1);
lean_inc(x_65);
lean_inc(x_64);
lean_dec(x_25);
x_66 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_66, 0, x_64);
lean_ctor_set(x_66, 1, x_65);
return x_66;
}
}
}
}
else
{
uint8_t x_67; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_2);
lean_dec(x_1);
x_67 = !lean_is_exclusive(x_14);
if (x_67 == 0)
{
return x_14;
}
else
{
lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_68 = lean_ctor_get(x_14, 0);
x_69 = lean_ctor_get(x_14, 1);
lean_inc(x_69);
lean_inc(x_68);
lean_dec(x_14);
x_70 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_70, 0, x_68);
lean_ctor_set(x_70, 1, x_69);
return x_70;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; 
x_13 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_13 == 0)
{
lean_object* x_14; lean_object* x_15; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_15 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_15, 0, x_14);
lean_ctor_set(x_15, 1, x_12);
return x_15;
}
else
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_box(0);
x_17 = l_BitVec_reduceShift___lambda__1(x_4, x_3, x_16, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
return x_17;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShift___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceShift___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1(lean_object* x_1, lean_object* x_2, uint8_t x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; 
lean_inc(x_1);
x_13 = l_Lean_Expr_appFn_x21(x_1);
x_14 = l_Lean_Expr_appArg_x21(x_13);
lean_dec(x_13);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_15 = l_BitVec_fromExpr_x3f(x_14, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_14);
if (lean_obj_tag(x_15) == 0)
{
lean_object* x_16; 
x_16 = lean_ctor_get(x_15, 0);
lean_inc(x_16);
if (lean_obj_tag(x_16) == 0)
{
uint8_t x_17; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_2);
lean_dec(x_1);
x_17 = !lean_is_exclusive(x_15);
if (x_17 == 0)
{
lean_object* x_18; lean_object* x_19; 
x_18 = lean_ctor_get(x_15, 0);
lean_dec(x_18);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_15, 0, x_19);
return x_15;
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; 
x_20 = lean_ctor_get(x_15, 1);
lean_inc(x_20);
lean_dec(x_15);
x_21 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_22 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_22, 0, x_21);
lean_ctor_set(x_22, 1, x_20);
return x_22;
}
}
else
{
lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; 
x_23 = lean_ctor_get(x_15, 1);
lean_inc(x_23);
lean_dec(x_15);
x_24 = lean_ctor_get(x_16, 0);
lean_inc(x_24);
lean_dec(x_16);
x_25 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_11);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
x_26 = l_BitVec_fromExpr_x3f(x_25, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_23);
lean_dec(x_25);
if (lean_obj_tag(x_26) == 0)
{
lean_object* x_27; 
x_27 = lean_ctor_get(x_26, 0);
lean_inc(x_27);
if (lean_obj_tag(x_27) == 0)
{
uint8_t x_28; 
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_2);
lean_dec(x_1);
x_28 = !lean_is_exclusive(x_26);
if (x_28 == 0)
{
lean_object* x_29; lean_object* x_30; 
x_29 = lean_ctor_get(x_26, 0);
lean_dec(x_29);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_26, 0, x_30);
return x_26;
}
else
{
lean_object* x_31; lean_object* x_32; lean_object* x_33; 
x_31 = lean_ctor_get(x_26, 1);
lean_inc(x_31);
lean_dec(x_26);
x_32 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_33 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_33, 0, x_32);
lean_ctor_set(x_33, 1, x_31);
return x_33;
}
}
else
{
uint8_t x_34; 
x_34 = !lean_is_exclusive(x_26);
if (x_34 == 0)
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; uint8_t x_40; 
x_35 = lean_ctor_get(x_26, 1);
x_36 = lean_ctor_get(x_26, 0);
lean_dec(x_36);
x_37 = lean_ctor_get(x_27, 0);
lean_inc(x_37);
lean_dec(x_27);
x_38 = lean_ctor_get(x_24, 0);
lean_inc(x_38);
x_39 = lean_ctor_get(x_37, 0);
lean_inc(x_39);
x_40 = lean_nat_dec_eq(x_38, x_39);
lean_dec(x_39);
if (x_40 == 0)
{
lean_object* x_41; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_2);
lean_dec(x_1);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_26, 0, x_41);
return x_26;
}
else
{
lean_object* x_42; lean_object* x_43; lean_object* x_44; uint8_t x_45; 
x_42 = lean_ctor_get(x_24, 1);
lean_inc(x_42);
lean_dec(x_24);
x_43 = lean_ctor_get(x_37, 1);
lean_inc(x_43);
lean_dec(x_37);
x_44 = lean_apply_3(x_2, x_38, x_42, x_43);
x_45 = lean_unbox(x_44);
lean_dec(x_44);
if (x_3 == 0)
{
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_1);
if (x_45 == 0)
{
lean_object* x_46; 
x_46 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_26, 0, x_46);
return x_26;
}
else
{
lean_object* x_47; 
x_47 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_26, 0, x_47);
return x_26;
}
}
else
{
lean_object* x_48; 
lean_free_object(x_26);
x_48 = l_Lean_Meta_Simp_evalPropStep(x_1, x_45, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_35);
return x_48;
}
}
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_49 = lean_ctor_get(x_26, 1);
lean_inc(x_49);
lean_dec(x_26);
x_50 = lean_ctor_get(x_27, 0);
lean_inc(x_50);
lean_dec(x_27);
x_51 = lean_ctor_get(x_24, 0);
lean_inc(x_51);
x_52 = lean_ctor_get(x_50, 0);
lean_inc(x_52);
x_53 = lean_nat_dec_eq(x_51, x_52);
lean_dec(x_52);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
lean_dec(x_51);
lean_dec(x_50);
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_2);
lean_dec(x_1);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_49);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; uint8_t x_59; 
x_56 = lean_ctor_get(x_24, 1);
lean_inc(x_56);
lean_dec(x_24);
x_57 = lean_ctor_get(x_50, 1);
lean_inc(x_57);
lean_dec(x_50);
x_58 = lean_apply_3(x_2, x_51, x_56, x_57);
x_59 = lean_unbox(x_58);
lean_dec(x_58);
if (x_3 == 0)
{
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_1);
if (x_59 == 0)
{
lean_object* x_60; lean_object* x_61; 
x_60 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_49);
return x_61;
}
else
{
lean_object* x_62; lean_object* x_63; 
x_62 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_63 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_63, 0, x_62);
lean_ctor_set(x_63, 1, x_49);
return x_63;
}
}
else
{
lean_object* x_64; 
x_64 = l_Lean_Meta_Simp_evalPropStep(x_1, x_59, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_49);
return x_64;
}
}
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_24);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_2);
lean_dec(x_1);
x_65 = !lean_is_exclusive(x_26);
if (x_65 == 0)
{
return x_26;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_26, 0);
x_67 = lean_ctor_get(x_26, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_26);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
else
{
uint8_t x_69; 
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_2);
lean_dec(x_1);
x_69 = !lean_is_exclusive(x_15);
if (x_69 == 0)
{
return x_15;
}
else
{
lean_object* x_70; lean_object* x_71; lean_object* x_72; 
x_70 = lean_ctor_get(x_15, 0);
x_71 = lean_ctor_get(x_15, 1);
lean_inc(x_71);
lean_inc(x_70);
lean_dec(x_15);
x_72 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_72, 0, x_70);
lean_ctor_set(x_72, 1, x_71);
return x_72;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, uint8_t x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12, lean_object* x_13) {
_start:
{
uint8_t x_14; 
x_14 = l_Lean_Expr_isAppOfArity(x_4, x_1, x_2);
lean_dec(x_1);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
lean_dec(x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_4);
lean_dec(x_3);
x_15 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_16 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_16, 0, x_15);
lean_ctor_set(x_16, 1, x_13);
return x_16;
}
else
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_box(0);
x_18 = l_BitVec_reduceBinPred___lambda__1(x_4, x_3, x_5, x_17, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
return x_18;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
uint8_t x_13; lean_object* x_14; 
x_13 = lean_unbox(x_3);
lean_dec(x_3);
x_14 = l_BitVec_reduceBinPred___lambda__1(x_1, x_2, x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
return x_14;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceBinPred___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12, lean_object* x_13) {
_start:
{
uint8_t x_14; lean_object* x_15; 
x_14 = lean_unbox(x_5);
lean_dec(x_5);
x_15 = l_BitVec_reduceBinPred(x_1, x_2, x_3, x_4, x_14, x_6, x_7, x_8, x_9, x_10, x_11, x_12, x_13);
return x_15;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; uint32_t x_31; uint8_t x_32; lean_object* x_33; lean_object* x_34; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_BitVec_neg(x_23, x_24);
lean_dec(x_24);
x_26 = l_Lean_mkNatLit(x_23);
x_27 = l_Lean_mkNatLit(x_25);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_29 = l_Lean_mkAppB(x_28, x_26, x_27);
x_30 = lean_box(0);
x_31 = 0;
x_32 = 1;
x_33 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_33, 0, x_29);
lean_ctor_set(x_33, 1, x_30);
lean_ctor_set_uint32(x_33, sizeof(void*)*2, x_31);
lean_ctor_set_uint8(x_33, sizeof(void*)*2 + 4, x_32);
x_34 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_12, 0, x_34);
return x_12;
}
else
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint32_t x_45; uint8_t x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_35 = lean_ctor_get(x_12, 1);
lean_inc(x_35);
lean_dec(x_12);
x_36 = lean_ctor_get(x_13, 0);
lean_inc(x_36);
lean_dec(x_13);
x_37 = lean_ctor_get(x_36, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 1);
lean_inc(x_38);
lean_dec(x_36);
x_39 = l_BitVec_neg(x_37, x_38);
lean_dec(x_38);
x_40 = l_Lean_mkNatLit(x_37);
x_41 = l_Lean_mkNatLit(x_39);
x_42 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_43 = l_Lean_mkAppB(x_42, x_40, x_41);
x_44 = lean_box(0);
x_45 = 0;
x_46 = 1;
x_47 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_47, 0, x_43);
lean_ctor_set(x_47, 1, x_44);
lean_ctor_set_uint32(x_47, sizeof(void*)*2, x_45);
lean_ctor_set_uint8(x_47, sizeof(void*)*2 + 4, x_46);
x_48 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_48, 0, x_47);
x_49 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_49, 0, x_48);
lean_ctor_set(x_49, 1, x_35);
return x_49;
}
}
}
else
{
uint8_t x_50; 
x_50 = !lean_is_exclusive(x_12);
if (x_50 == 0)
{
return x_12;
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_51 = lean_ctor_get(x_12, 0);
x_52 = lean_ctor_get(x_12, 1);
lean_inc(x_52);
lean_inc(x_51);
lean_dec(x_12);
x_53 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
return x_53;
}
}
}
}
static lean_object* _init_l_BitVec_reduceNeg___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Neg", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNeg___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("neg", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNeg___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNeg___closed__1;
x_2 = l_BitVec_reduceNeg___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceNeg___closed__3;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceNeg___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceNeg___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNeg___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNeg(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceNeg", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNeg___closed__3;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_3 = l_Lean_Name_str___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__4;
x_2 = lean_unsigned_to_nat(1u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(5u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__7;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceNeg___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2;
x_3 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__11;
x_4 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = l_Lean_Meta_Simp_builtinSimprocsRef;
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = l_Lean_Meta_Simp_builtinSEvalprocsRef;
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; uint32_t x_31; uint8_t x_32; lean_object* x_33; lean_object* x_34; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_BitVec_not(x_23, x_24);
lean_dec(x_24);
x_26 = l_Lean_mkNatLit(x_23);
x_27 = l_Lean_mkNatLit(x_25);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_29 = l_Lean_mkAppB(x_28, x_26, x_27);
x_30 = lean_box(0);
x_31 = 0;
x_32 = 1;
x_33 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_33, 0, x_29);
lean_ctor_set(x_33, 1, x_30);
lean_ctor_set_uint32(x_33, sizeof(void*)*2, x_31);
lean_ctor_set_uint8(x_33, sizeof(void*)*2 + 4, x_32);
x_34 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_12, 0, x_34);
return x_12;
}
else
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint32_t x_45; uint8_t x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_35 = lean_ctor_get(x_12, 1);
lean_inc(x_35);
lean_dec(x_12);
x_36 = lean_ctor_get(x_13, 0);
lean_inc(x_36);
lean_dec(x_13);
x_37 = lean_ctor_get(x_36, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 1);
lean_inc(x_38);
lean_dec(x_36);
x_39 = l_BitVec_not(x_37, x_38);
lean_dec(x_38);
x_40 = l_Lean_mkNatLit(x_37);
x_41 = l_Lean_mkNatLit(x_39);
x_42 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_43 = l_Lean_mkAppB(x_42, x_40, x_41);
x_44 = lean_box(0);
x_45 = 0;
x_46 = 1;
x_47 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_47, 0, x_43);
lean_ctor_set(x_47, 1, x_44);
lean_ctor_set_uint32(x_47, sizeof(void*)*2, x_45);
lean_ctor_set_uint8(x_47, sizeof(void*)*2 + 4, x_46);
x_48 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_48, 0, x_47);
x_49 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_49, 0, x_48);
lean_ctor_set(x_49, 1, x_35);
return x_49;
}
}
}
else
{
uint8_t x_50; 
x_50 = !lean_is_exclusive(x_12);
if (x_50 == 0)
{
return x_12;
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_51 = lean_ctor_get(x_12, 0);
x_52 = lean_ctor_get(x_12, 1);
lean_inc(x_52);
lean_inc(x_51);
lean_dec(x_12);
x_53 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
return x_53;
}
}
}
}
static lean_object* _init_l_BitVec_reduceNot___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Complement", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNot___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("complement", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceNot___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNot___closed__1;
x_2 = l_BitVec_reduceNot___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceNot___closed__3;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceNot___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceNot___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceNot___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceNot(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceNot", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNot___closed__3;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceNot___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2;
x_3 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__8;
x_4 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1187_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1189_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; lean_object* x_29; lean_object* x_30; uint32_t x_31; uint8_t x_32; lean_object* x_33; lean_object* x_34; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_BitVec_abs(x_23, x_24);
lean_dec(x_24);
x_26 = l_Lean_mkNatLit(x_23);
x_27 = l_Lean_mkNatLit(x_25);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_29 = l_Lean_mkAppB(x_28, x_26, x_27);
x_30 = lean_box(0);
x_31 = 0;
x_32 = 1;
x_33 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_33, 0, x_29);
lean_ctor_set(x_33, 1, x_30);
lean_ctor_set_uint32(x_33, sizeof(void*)*2, x_31);
lean_ctor_set_uint8(x_33, sizeof(void*)*2 + 4, x_32);
x_34 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_34, 0, x_33);
lean_ctor_set(x_12, 0, x_34);
return x_12;
}
else
{
lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint32_t x_45; uint8_t x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_35 = lean_ctor_get(x_12, 1);
lean_inc(x_35);
lean_dec(x_12);
x_36 = lean_ctor_get(x_13, 0);
lean_inc(x_36);
lean_dec(x_13);
x_37 = lean_ctor_get(x_36, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 1);
lean_inc(x_38);
lean_dec(x_36);
x_39 = l_BitVec_abs(x_37, x_38);
lean_dec(x_38);
x_40 = l_Lean_mkNatLit(x_37);
x_41 = l_Lean_mkNatLit(x_39);
x_42 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_43 = l_Lean_mkAppB(x_42, x_40, x_41);
x_44 = lean_box(0);
x_45 = 0;
x_46 = 1;
x_47 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_47, 0, x_43);
lean_ctor_set(x_47, 1, x_44);
lean_ctor_set_uint32(x_47, sizeof(void*)*2, x_45);
lean_ctor_set_uint8(x_47, sizeof(void*)*2 + 4, x_46);
x_48 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_48, 0, x_47);
x_49 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_49, 0, x_48);
lean_ctor_set(x_49, 1, x_35);
return x_49;
}
}
}
else
{
uint8_t x_50; 
x_50 = !lean_is_exclusive(x_12);
if (x_50 == 0)
{
return x_12;
}
else
{
lean_object* x_51; lean_object* x_52; lean_object* x_53; 
x_51 = lean_ctor_get(x_12, 0);
x_52 = lean_ctor_get(x_12, 1);
lean_inc(x_52);
lean_inc(x_51);
lean_dec(x_12);
x_53 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
return x_53;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAbs___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("abs", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAbs___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceAbs___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAbs___closed__2;
x_11 = lean_unsigned_to_nat(2u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAbs___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceAbs___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAbs___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAbs(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAbs", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAbs___closed__2;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(3u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAbs___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__7;
x_4 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1208_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1210_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = lean_nat_land(x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceAnd___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceAnd___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceAnd___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceAnd___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAnd___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HAnd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAnd___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hAnd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAnd___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAnd___closed__1;
x_2 = l_BitVec_reduceAnd___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAnd___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAnd___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAnd___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceAnd___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAnd", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAnd___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(10u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__5;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__7;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__9;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__14() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__13;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAnd), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__14;
x_4 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1250_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = lean_nat_lor(x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceOr___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceOr___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceOr___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceOr___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceOr___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HOr", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOr___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hOr", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOr___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOr___closed__1;
x_2 = l_BitVec_reduceOr___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceOr___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceOr___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOr___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceOr___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceOr", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOr___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOr), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__13;
x_4 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1292_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = lean_nat_lxor(x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceXOr___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceXOr___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceXOr___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceXOr___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceXOr___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HXor", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceXOr___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hXor", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceXOr___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceXOr___closed__1;
x_2 = l_BitVec_reduceXOr___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceXOr___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceXOr___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceXOr___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceXOr___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceXOr", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceXOr___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceXOr), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2;
x_3 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__13;
x_4 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1334_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_add(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceAdd___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceAdd___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceAdd___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceAdd___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAdd___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HAdd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAdd___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hAdd", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAdd___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAdd___closed__1;
x_2 = l_BitVec_reduceAdd___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAdd___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAdd___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAdd___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceAdd___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAdd", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAdd___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAdd), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__13;
x_4 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1376_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_mul(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceMul___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceMul___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceMul___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceMul___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceMul___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HMul", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMul___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hMul", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMul___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMul___closed__1;
x_2 = l_BitVec_reduceMul___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceMul___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceMul___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMul___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceMul___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceMul", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMul___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceMul), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2;
x_3 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__13;
x_4 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1418_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_sub(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceSub___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceSub___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceSub___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceSub___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSub___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HSub", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSub___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hSub", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSub___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSub___closed__1;
x_2 = l_BitVec_reduceSub___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSub___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSub___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSub___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceSub___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSub", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSub___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSub), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__13;
x_4 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1460_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = lean_nat_div(x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceDiv___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceDiv___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceDiv___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceDiv___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HDiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceDiv___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hDiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceDiv___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceDiv___closed__1;
x_2 = l_BitVec_reduceDiv___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceDiv___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceDiv___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceDiv", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceDiv___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2;
x_3 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__13;
x_4 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1502_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = lean_nat_mod(x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceMod___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceMod___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceMod___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceMod___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceMod___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HMod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMod___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hMod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceMod___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMod___closed__1;
x_2 = l_BitVec_reduceMod___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceMod___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceMod___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceMod___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceMod___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceMod", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceMod___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4;
x_2 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__8;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__13() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__12;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceMod), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2;
x_3 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__13;
x_4 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1544_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceUMod___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("umod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUMod___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUMod___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceUMod___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceMod___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceUMod", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUMod___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(4u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUMod), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__8;
x_4 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1570_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1572_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceUDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("udiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceUDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceDiv___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceUDiv", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__7;
x_4 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_smtUDiv(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceSMTUDiv___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceSMTUDiv___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceSMTUDiv___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceSMTUDiv___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSMTUDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("smtUDiv", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMTUDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSMTUDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSMTUDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSMTUDiv___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTUDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceSMTUDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSMTUDiv", 13);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMTUDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMTUDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1622_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1624_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_smod(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceSMod___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceSMod___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceSMod___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceSMod___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSMod___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("smod", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMod___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSMod___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSMod___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSMod___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMod___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceSMod___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSMod", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMod___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMod), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1648_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1650_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_srem(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceSRem___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceSRem___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceSRem___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceSRem___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSRem___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("srem", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSRem___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSRem___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSRem___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSRem___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSRem___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceSRem___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSRem", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSRem___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSRem), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1674_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_sdiv(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceSDiv___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceSDiv___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceSDiv___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceSDiv___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("sdiv", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSDiv___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceSDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSDiv", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1700_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1702_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; lean_object* x_17; lean_object* x_18; lean_object* x_19; lean_object* x_20; uint32_t x_21; uint8_t x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_13 = lean_ctor_get(x_1, 1);
x_14 = lean_ctor_get(x_2, 1);
x_15 = l_BitVec_smtSDiv(x_3, x_13, x_14);
x_16 = l_Lean_mkNatLit(x_3);
x_17 = l_Lean_mkNatLit(x_15);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_19 = l_Lean_mkAppB(x_18, x_16, x_17);
x_20 = lean_box(0);
x_21 = 0;
x_22 = 1;
x_23 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_23, 0, x_19);
lean_ctor_set(x_23, 1, x_20);
lean_ctor_set_uint32(x_23, sizeof(void*)*2, x_21);
lean_ctor_set_uint8(x_23, sizeof(void*)*2 + 4, x_22);
x_24 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_24, 0, x_23);
x_25 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_25, 0, x_24);
lean_ctor_set(x_25, 1, x_12);
return x_25;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; 
lean_dec(x_3);
lean_inc(x_1);
x_12 = l_Lean_Expr_appFn_x21(x_1);
x_13 = l_Lean_Expr_appArg_x21(x_12);
lean_dec(x_12);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_14 = l_BitVec_fromExpr_x3f(x_13, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_13);
if (lean_obj_tag(x_14) == 0)
{
lean_object* x_15; 
x_15 = lean_ctor_get(x_14, 0);
lean_inc(x_15);
if (lean_obj_tag(x_15) == 0)
{
uint8_t x_16; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_16 = !lean_is_exclusive(x_14);
if (x_16 == 0)
{
lean_object* x_17; lean_object* x_18; 
x_17 = lean_ctor_get(x_14, 0);
lean_dec(x_17);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_14, 0, x_18);
return x_14;
}
else
{
lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_19 = lean_ctor_get(x_14, 1);
lean_inc(x_19);
lean_dec(x_14);
x_20 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_19);
return x_21;
}
}
else
{
lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_22 = lean_ctor_get(x_14, 1);
lean_inc(x_22);
lean_dec(x_14);
x_23 = lean_ctor_get(x_15, 0);
lean_inc(x_23);
lean_dec(x_15);
x_24 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_10);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
x_25 = l_BitVec_fromExpr_x3f(x_24, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_22);
lean_dec(x_24);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; uint8_t x_39; 
x_34 = lean_ctor_get(x_25, 1);
x_35 = lean_ctor_get(x_25, 0);
lean_dec(x_35);
x_36 = lean_ctor_get(x_26, 0);
lean_inc(x_36);
lean_dec(x_26);
x_37 = lean_ctor_get(x_23, 0);
lean_inc(x_37);
x_38 = lean_ctor_get(x_36, 0);
lean_inc(x_38);
x_39 = lean_nat_dec_eq(x_37, x_38);
if (x_39 == 0)
{
lean_object* x_40; 
lean_dec(x_38);
lean_dec(x_37);
lean_dec(x_36);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_40);
return x_25;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
lean_free_object(x_25);
x_41 = l_BitVec_reduceBin___lambda__2___closed__3;
x_42 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_41, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_34);
x_43 = lean_ctor_get(x_42, 0);
lean_inc(x_43);
x_44 = lean_unbox(x_43);
lean_dec(x_43);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; 
lean_dec(x_38);
lean_dec(x_2);
x_45 = lean_ctor_get(x_42, 1);
lean_inc(x_45);
lean_dec(x_42);
x_46 = lean_box(0);
x_47 = l_BitVec_reduceSMTSDiv___lambda__1(x_23, x_36, x_37, x_46, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_45);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_36);
lean_dec(x_23);
return x_47;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; lean_object* x_72; lean_object* x_73; lean_object* x_74; lean_object* x_75; lean_object* x_76; lean_object* x_77; lean_object* x_78; lean_object* x_79; lean_object* x_80; lean_object* x_81; lean_object* x_82; lean_object* x_83; lean_object* x_84; lean_object* x_85; lean_object* x_86; lean_object* x_87; lean_object* x_88; lean_object* x_89; 
x_48 = lean_ctor_get(x_42, 1);
lean_inc(x_48);
lean_dec(x_42);
x_49 = l_Lean_MessageData_ofName(x_2);
x_50 = l_BitVec_reduceBin___lambda__2___closed__5;
x_51 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_49);
x_52 = l_BitVec_reduceBin___lambda__2___closed__7;
x_53 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_53, 0, x_51);
lean_ctor_set(x_53, 1, x_52);
x_54 = lean_ctor_get(x_23, 1);
lean_inc(x_54);
x_55 = l_BitVec_toHex(x_37, x_54);
x_56 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = l_BitVec_reduceBin___lambda__2___closed__9;
x_58 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_58, 0, x_57);
lean_ctor_set(x_58, 1, x_56);
x_59 = l_BitVec_reduceBin___lambda__2___closed__11;
x_60 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_60, 0, x_58);
lean_ctor_set(x_60, 1, x_59);
lean_inc(x_37);
x_61 = l_Nat_repr(x_37);
x_62 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_63, 0, x_60);
lean_ctor_set(x_63, 1, x_62);
x_64 = l_Std_Format_defWidth;
x_65 = lean_unsigned_to_nat(0u);
x_66 = lean_format_pretty(x_63, x_64, x_65, x_65);
x_67 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_67, 0, x_66);
x_68 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_68, 0, x_67);
x_69 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_69, 0, x_53);
lean_ctor_set(x_69, 1, x_68);
x_70 = l_BitVec_reduceBin___lambda__2___closed__13;
x_71 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
x_72 = lean_ctor_get(x_36, 1);
lean_inc(x_72);
x_73 = l_BitVec_toHex(x_38, x_72);
x_74 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_74, 0, x_73);
x_75 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_75, 0, x_57);
lean_ctor_set(x_75, 1, x_74);
x_76 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_76, 0, x_75);
lean_ctor_set(x_76, 1, x_59);
x_77 = l_Nat_repr(x_38);
x_78 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_78, 0, x_77);
x_79 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_79, 0, x_76);
lean_ctor_set(x_79, 1, x_78);
x_80 = lean_format_pretty(x_79, x_64, x_65, x_65);
x_81 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_81, 0, x_80);
x_82 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_82, 0, x_81);
x_83 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_83, 0, x_71);
lean_ctor_set(x_83, 1, x_82);
x_84 = l_BitVec_reduceBin___lambda__2___closed__15;
x_85 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_85, 0, x_83);
lean_ctor_set(x_85, 1, x_84);
x_86 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_41, x_85, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_48);
x_87 = lean_ctor_get(x_86, 0);
lean_inc(x_87);
x_88 = lean_ctor_get(x_86, 1);
lean_inc(x_88);
lean_dec(x_86);
x_89 = l_BitVec_reduceSMTSDiv___lambda__1(x_23, x_36, x_37, x_87, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_88);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_87);
lean_dec(x_36);
lean_dec(x_23);
return x_89;
}
}
}
else
{
lean_object* x_90; lean_object* x_91; lean_object* x_92; lean_object* x_93; uint8_t x_94; 
x_90 = lean_ctor_get(x_25, 1);
lean_inc(x_90);
lean_dec(x_25);
x_91 = lean_ctor_get(x_26, 0);
lean_inc(x_91);
lean_dec(x_26);
x_92 = lean_ctor_get(x_23, 0);
lean_inc(x_92);
x_93 = lean_ctor_get(x_91, 0);
lean_inc(x_93);
x_94 = lean_nat_dec_eq(x_92, x_93);
if (x_94 == 0)
{
lean_object* x_95; lean_object* x_96; 
lean_dec(x_93);
lean_dec(x_92);
lean_dec(x_91);
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_95 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_96 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_96, 0, x_95);
lean_ctor_set(x_96, 1, x_90);
return x_96;
}
else
{
lean_object* x_97; lean_object* x_98; lean_object* x_99; uint8_t x_100; 
x_97 = l_BitVec_reduceBin___lambda__2___closed__3;
x_98 = l_Lean_isTracingEnabledFor___at_Lean_Meta_Simp_congrArgs___spec__1(x_97, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_90);
x_99 = lean_ctor_get(x_98, 0);
lean_inc(x_99);
x_100 = lean_unbox(x_99);
lean_dec(x_99);
if (x_100 == 0)
{
lean_object* x_101; lean_object* x_102; lean_object* x_103; 
lean_dec(x_93);
lean_dec(x_2);
x_101 = lean_ctor_get(x_98, 1);
lean_inc(x_101);
lean_dec(x_98);
x_102 = lean_box(0);
x_103 = l_BitVec_reduceSMTSDiv___lambda__1(x_23, x_91, x_92, x_102, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_101);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_91);
lean_dec(x_23);
return x_103;
}
else
{
lean_object* x_104; lean_object* x_105; lean_object* x_106; lean_object* x_107; lean_object* x_108; lean_object* x_109; lean_object* x_110; lean_object* x_111; lean_object* x_112; lean_object* x_113; lean_object* x_114; lean_object* x_115; lean_object* x_116; lean_object* x_117; lean_object* x_118; lean_object* x_119; lean_object* x_120; lean_object* x_121; lean_object* x_122; lean_object* x_123; lean_object* x_124; lean_object* x_125; lean_object* x_126; lean_object* x_127; lean_object* x_128; lean_object* x_129; lean_object* x_130; lean_object* x_131; lean_object* x_132; lean_object* x_133; lean_object* x_134; lean_object* x_135; lean_object* x_136; lean_object* x_137; lean_object* x_138; lean_object* x_139; lean_object* x_140; lean_object* x_141; lean_object* x_142; lean_object* x_143; lean_object* x_144; lean_object* x_145; 
x_104 = lean_ctor_get(x_98, 1);
lean_inc(x_104);
lean_dec(x_98);
x_105 = l_Lean_MessageData_ofName(x_2);
x_106 = l_BitVec_reduceBin___lambda__2___closed__5;
x_107 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_107, 0, x_106);
lean_ctor_set(x_107, 1, x_105);
x_108 = l_BitVec_reduceBin___lambda__2___closed__7;
x_109 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_109, 0, x_107);
lean_ctor_set(x_109, 1, x_108);
x_110 = lean_ctor_get(x_23, 1);
lean_inc(x_110);
x_111 = l_BitVec_toHex(x_92, x_110);
x_112 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_112, 0, x_111);
x_113 = l_BitVec_reduceBin___lambda__2___closed__9;
x_114 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_114, 0, x_113);
lean_ctor_set(x_114, 1, x_112);
x_115 = l_BitVec_reduceBin___lambda__2___closed__11;
x_116 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_116, 0, x_114);
lean_ctor_set(x_116, 1, x_115);
lean_inc(x_92);
x_117 = l_Nat_repr(x_92);
x_118 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_118, 0, x_117);
x_119 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_119, 0, x_116);
lean_ctor_set(x_119, 1, x_118);
x_120 = l_Std_Format_defWidth;
x_121 = lean_unsigned_to_nat(0u);
x_122 = lean_format_pretty(x_119, x_120, x_121, x_121);
x_123 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_123, 0, x_122);
x_124 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_124, 0, x_123);
x_125 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_125, 0, x_109);
lean_ctor_set(x_125, 1, x_124);
x_126 = l_BitVec_reduceBin___lambda__2___closed__13;
x_127 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_127, 0, x_125);
lean_ctor_set(x_127, 1, x_126);
x_128 = lean_ctor_get(x_91, 1);
lean_inc(x_128);
x_129 = l_BitVec_toHex(x_93, x_128);
x_130 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_130, 0, x_129);
x_131 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_131, 0, x_113);
lean_ctor_set(x_131, 1, x_130);
x_132 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_132, 0, x_131);
lean_ctor_set(x_132, 1, x_115);
x_133 = l_Nat_repr(x_93);
x_134 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_134, 0, x_133);
x_135 = lean_alloc_ctor(5, 2, 0);
lean_ctor_set(x_135, 0, x_132);
lean_ctor_set(x_135, 1, x_134);
x_136 = lean_format_pretty(x_135, x_120, x_121, x_121);
x_137 = lean_alloc_ctor(3, 1, 0);
lean_ctor_set(x_137, 0, x_136);
x_138 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_138, 0, x_137);
x_139 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_139, 0, x_127);
lean_ctor_set(x_139, 1, x_138);
x_140 = l_BitVec_reduceBin___lambda__2___closed__15;
x_141 = lean_alloc_ctor(7, 2, 0);
lean_ctor_set(x_141, 0, x_139);
lean_ctor_set(x_141, 1, x_140);
x_142 = l_Lean_addTrace___at_Lean_Meta_Simp_congrArgs___spec__2(x_97, x_141, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_104);
x_143 = lean_ctor_get(x_142, 0);
lean_inc(x_143);
x_144 = lean_ctor_get(x_142, 1);
lean_inc(x_144);
lean_dec(x_142);
x_145 = l_BitVec_reduceSMTSDiv___lambda__1(x_23, x_91, x_92, x_143, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_144);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_143);
lean_dec(x_91);
lean_dec(x_23);
return x_145;
}
}
}
}
}
else
{
uint8_t x_146; 
lean_dec(x_23);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
x_146 = !lean_is_exclusive(x_25);
if (x_146 == 0)
{
return x_25;
}
else
{
lean_object* x_147; lean_object* x_148; lean_object* x_149; 
x_147 = lean_ctor_get(x_25, 0);
x_148 = lean_ctor_get(x_25, 1);
lean_inc(x_148);
lean_inc(x_147);
lean_dec(x_25);
x_149 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_149, 0, x_147);
lean_ctor_set(x_149, 1, x_148);
return x_149;
}
}
}
}
else
{
uint8_t x_150; 
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
x_150 = !lean_is_exclusive(x_14);
if (x_150 == 0)
{
return x_14;
}
else
{
lean_object* x_151; lean_object* x_152; lean_object* x_153; 
x_151 = lean_ctor_get(x_14, 0);
x_152 = lean_ctor_get(x_14, 1);
lean_inc(x_152);
lean_inc(x_151);
lean_dec(x_14);
x_153 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_153, 0, x_151);
lean_ctor_set(x_153, 1, x_152);
return x_153;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSMTSDiv___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("smtSDiv", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSMTSDiv___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSMTSDiv___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSMTSDiv___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSMTSDiv___lambda__2(x_1, x_10, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSMTSDiv___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11, lean_object* x_12) {
_start:
{
lean_object* x_13; 
x_13 = l_BitVec_reduceSMTSDiv___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11, x_12);
lean_dec(x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_2);
lean_dec(x_1);
return x_13;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSMTSDiv", 13);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSMTSDiv___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSMTSDiv), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1726_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1728_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; uint8_t x_36; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 1);
lean_inc(x_35);
lean_dec(x_22);
x_36 = l_Nat_testBit(x_35, x_34);
lean_dec(x_34);
lean_dec(x_35);
if (x_36 == 0)
{
lean_object* x_37; 
x_37 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_24, 0, x_37);
return x_24;
}
else
{
lean_object* x_38; 
x_38 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_39 = lean_ctor_get(x_24, 1);
lean_inc(x_39);
lean_dec(x_24);
x_40 = lean_ctor_get(x_25, 0);
lean_inc(x_40);
lean_dec(x_25);
x_41 = lean_ctor_get(x_22, 1);
lean_inc(x_41);
lean_dec(x_22);
x_42 = l_Nat_testBit(x_41, x_40);
lean_dec(x_40);
lean_dec(x_41);
if (x_42 == 0)
{
lean_object* x_43; lean_object* x_44; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_44 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_44, 0, x_43);
lean_ctor_set(x_44, 1, x_39);
return x_44;
}
else
{
lean_object* x_45; lean_object* x_46; 
x_45 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_46 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_46, 1, x_39);
return x_46;
}
}
}
}
else
{
uint8_t x_47; 
lean_dec(x_22);
x_47 = !lean_is_exclusive(x_24);
if (x_47 == 0)
{
return x_24;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; 
x_48 = lean_ctor_get(x_24, 0);
x_49 = lean_ctor_get(x_24, 1);
lean_inc(x_49);
lean_inc(x_48);
lean_dec(x_24);
x_50 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_50, 0, x_48);
lean_ctor_set(x_50, 1, x_49);
return x_50;
}
}
}
}
else
{
uint8_t x_51; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_51 = !lean_is_exclusive(x_13);
if (x_51 == 0)
{
return x_13;
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; 
x_52 = lean_ctor_get(x_13, 0);
x_53 = lean_ctor_get(x_13, 1);
lean_inc(x_53);
lean_inc(x_52);
lean_dec(x_13);
x_54 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_54, 0, x_52);
lean_ctor_set(x_54, 1, x_53);
return x_54;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGetLsb___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("getLsb", 6);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetLsb___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceGetLsb___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGetLsb___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGetLsb___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetLsb___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGetLsb___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGetLsb", 12);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetLsb___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGetLsb), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__7;
x_4 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1747_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1749_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = lean_nat_dec_lt(x_34, x_35);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_36);
lean_dec(x_35);
lean_dec(x_34);
x_38 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; uint8_t x_42; 
x_39 = lean_unsigned_to_nat(1u);
x_40 = lean_nat_sub(x_35, x_39);
lean_dec(x_35);
x_41 = lean_nat_sub(x_40, x_34);
lean_dec(x_34);
lean_dec(x_40);
x_42 = l_Nat_testBit(x_36, x_41);
lean_dec(x_41);
lean_dec(x_36);
if (x_42 == 0)
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
else
{
lean_object* x_44; 
x_44 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_24, 0, x_44);
return x_24;
}
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; uint8_t x_49; 
x_45 = lean_ctor_get(x_24, 1);
lean_inc(x_45);
lean_dec(x_24);
x_46 = lean_ctor_get(x_25, 0);
lean_inc(x_46);
lean_dec(x_25);
x_47 = lean_ctor_get(x_22, 0);
lean_inc(x_47);
x_48 = lean_ctor_get(x_22, 1);
lean_inc(x_48);
lean_dec(x_22);
x_49 = lean_nat_dec_lt(x_46, x_47);
if (x_49 == 0)
{
lean_object* x_50; lean_object* x_51; 
lean_dec(x_48);
lean_dec(x_47);
lean_dec(x_46);
x_50 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_51 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_51, 0, x_50);
lean_ctor_set(x_51, 1, x_45);
return x_51;
}
else
{
lean_object* x_52; lean_object* x_53; lean_object* x_54; uint8_t x_55; 
x_52 = lean_unsigned_to_nat(1u);
x_53 = lean_nat_sub(x_47, x_52);
lean_dec(x_47);
x_54 = lean_nat_sub(x_53, x_46);
lean_dec(x_46);
lean_dec(x_53);
x_55 = l_Nat_testBit(x_48, x_54);
lean_dec(x_54);
lean_dec(x_48);
if (x_55 == 0)
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_45);
return x_57;
}
else
{
lean_object* x_58; lean_object* x_59; 
x_58 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_59 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_59, 0, x_58);
lean_ctor_set(x_59, 1, x_45);
return x_59;
}
}
}
}
}
else
{
uint8_t x_60; 
lean_dec(x_22);
x_60 = !lean_is_exclusive(x_24);
if (x_60 == 0)
{
return x_24;
}
else
{
lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_61 = lean_ctor_get(x_24, 0);
x_62 = lean_ctor_get(x_24, 1);
lean_inc(x_62);
lean_inc(x_61);
lean_dec(x_24);
x_63 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_63, 0, x_61);
lean_ctor_set(x_63, 1, x_62);
return x_63;
}
}
}
}
else
{
uint8_t x_64; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_64 = !lean_is_exclusive(x_13);
if (x_64 == 0)
{
return x_13;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_65 = lean_ctor_get(x_13, 0);
x_66 = lean_ctor_get(x_13, 1);
lean_inc(x_66);
lean_inc(x_65);
lean_dec(x_13);
x_67 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_67, 0, x_65);
lean_ctor_set(x_67, 1, x_66);
return x_67;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGetMsb___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("getMsb", 6);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGetMsb___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceGetMsb___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGetMsb___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGetMsb___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGetMsb___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGetMsb___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGetMsb", 12);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGetMsb___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGetMsb), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2;
x_3 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__7;
x_4 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1768_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_shiftLeft(x_35, x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; uint32_t x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_22, 1);
lean_inc(x_50);
lean_dec(x_22);
x_51 = l_BitVec_shiftLeft(x_49, x_50, x_48);
lean_dec(x_48);
lean_dec(x_50);
x_52 = l_Lean_mkNatLit(x_49);
x_53 = l_Lean_mkNatLit(x_51);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_55 = l_Lean_mkAppB(x_54, x_52, x_53);
x_56 = lean_box(0);
x_57 = 0;
x_58 = 1;
x_59 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_59, 0, x_55);
lean_ctor_set(x_59, 1, x_56);
lean_ctor_set_uint32(x_59, sizeof(void*)*2, x_57);
lean_ctor_set_uint8(x_59, sizeof(void*)*2 + 4, x_58);
x_60 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_60, 0, x_59);
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_47);
return x_61;
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_22);
x_62 = !lean_is_exclusive(x_24);
if (x_62 == 0)
{
return x_24;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_24, 0);
x_64 = lean_ctor_get(x_24, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_24);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_66 = !lean_is_exclusive(x_13);
if (x_66 == 0)
{
return x_13;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_13, 0);
x_68 = lean_ctor_get(x_13, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_13);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
static lean_object* _init_l_BitVec_reduceShiftLeft___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("shiftLeft", 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeft___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceShiftLeft___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceShiftLeft___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceShiftLeft___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeft___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceShiftLeft___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceShiftLeft", 15);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftLeft___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeft), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2;
x_3 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__7;
x_4 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1790_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1792_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = lean_nat_shiftr(x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; uint32_t x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_22, 1);
lean_inc(x_50);
lean_dec(x_22);
x_51 = lean_nat_shiftr(x_50, x_48);
lean_dec(x_48);
lean_dec(x_50);
x_52 = l_Lean_mkNatLit(x_49);
x_53 = l_Lean_mkNatLit(x_51);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_55 = l_Lean_mkAppB(x_54, x_52, x_53);
x_56 = lean_box(0);
x_57 = 0;
x_58 = 1;
x_59 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_59, 0, x_55);
lean_ctor_set(x_59, 1, x_56);
lean_ctor_set_uint32(x_59, sizeof(void*)*2, x_57);
lean_ctor_set_uint8(x_59, sizeof(void*)*2 + 4, x_58);
x_60 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_60, 0, x_59);
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_47);
return x_61;
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_22);
x_62 = !lean_is_exclusive(x_24);
if (x_62 == 0)
{
return x_24;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_24, 0);
x_64 = lean_ctor_get(x_24, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_24);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_66 = !lean_is_exclusive(x_13);
if (x_66 == 0)
{
return x_13;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_13, 0);
x_68 = lean_ctor_get(x_13, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_13);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
static lean_object* _init_l_BitVec_reduceUShiftRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ushiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceUShiftRight___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceUShiftRight___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceUShiftRight___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceUShiftRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceUShiftRight___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceUShiftRight___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceUShiftRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUShiftRight___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceUShiftRight), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2;
x_3 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__7;
x_4 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_sshiftRight(x_35, x_36, x_34);
lean_dec(x_34);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; uint32_t x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_22, 1);
lean_inc(x_50);
lean_dec(x_22);
x_51 = l_BitVec_sshiftRight(x_49, x_50, x_48);
lean_dec(x_48);
x_52 = l_Lean_mkNatLit(x_49);
x_53 = l_Lean_mkNatLit(x_51);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_55 = l_Lean_mkAppB(x_54, x_52, x_53);
x_56 = lean_box(0);
x_57 = 0;
x_58 = 1;
x_59 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_59, 0, x_55);
lean_ctor_set(x_59, 1, x_56);
lean_ctor_set_uint32(x_59, sizeof(void*)*2, x_57);
lean_ctor_set_uint8(x_59, sizeof(void*)*2 + 4, x_58);
x_60 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_60, 0, x_59);
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_47);
return x_61;
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_22);
x_62 = !lean_is_exclusive(x_24);
if (x_62 == 0)
{
return x_24;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_24, 0);
x_64 = lean_ctor_get(x_24, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_24);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_66 = !lean_is_exclusive(x_13);
if (x_66 == 0)
{
return x_13;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_13, 0);
x_68 = lean_ctor_get(x_13, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_13);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSShiftRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("sshiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSShiftRight___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSShiftRight___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSShiftRight___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSShiftRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSShiftRight___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSShiftRight___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSShiftRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSShiftRight___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSShiftRight), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HShiftLeft", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hShiftLeft", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftLeft___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftLeft___closed__1;
x_2 = l_BitVec_reduceHShiftLeft___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceHShiftLeft___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceShiftLeft___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftLeft___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftLeft(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceHShiftLeft", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftLeft___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(8u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4;
x_2 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__7;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__12() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__11;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftLeft___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2;
x_3 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__12;
x_4 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HShiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hShiftRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceHShiftRight___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftRight___closed__1;
x_2 = l_BitVec_reduceHShiftRight___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceHShiftRight___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceUShiftRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceHShiftRight___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceHShiftRight(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceHShiftRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceHShiftRight___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4;
x_2 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceHShiftRight___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2;
x_3 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__11;
x_4 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_rotateLeft(x_35, x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; uint32_t x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_22, 1);
lean_inc(x_50);
lean_dec(x_22);
x_51 = l_BitVec_rotateLeft(x_49, x_50, x_48);
lean_dec(x_48);
lean_dec(x_50);
x_52 = l_Lean_mkNatLit(x_49);
x_53 = l_Lean_mkNatLit(x_51);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_55 = l_Lean_mkAppB(x_54, x_52, x_53);
x_56 = lean_box(0);
x_57 = 0;
x_58 = 1;
x_59 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_59, 0, x_55);
lean_ctor_set(x_59, 1, x_56);
lean_ctor_set_uint32(x_59, sizeof(void*)*2, x_57);
lean_ctor_set_uint8(x_59, sizeof(void*)*2 + 4, x_58);
x_60 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_60, 0, x_59);
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_47);
return x_61;
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_22);
x_62 = !lean_is_exclusive(x_24);
if (x_62 == 0)
{
return x_24;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_24, 0);
x_64 = lean_ctor_get(x_24, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_24);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_66 = !lean_is_exclusive(x_13);
if (x_66 == 0)
{
return x_13;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_13, 0);
x_68 = lean_ctor_get(x_13, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_13);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
static lean_object* _init_l_BitVec_reduceRotateLeft___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("rotateLeft", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceRotateLeft___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceRotateLeft___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceRotateLeft___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceRotateLeft___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateLeft___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceRotateLeft___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceRotateLeft", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceRotateLeft___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceRotateLeft), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2;
x_3 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__7;
x_4 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1940_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1942_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_22, 1);
lean_inc(x_36);
lean_dec(x_22);
x_37 = l_BitVec_rotateRight(x_35, x_36, x_34);
lean_dec(x_34);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; uint32_t x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_22, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_22, 1);
lean_inc(x_50);
lean_dec(x_22);
x_51 = l_BitVec_rotateRight(x_49, x_50, x_48);
lean_dec(x_48);
lean_dec(x_50);
x_52 = l_Lean_mkNatLit(x_49);
x_53 = l_Lean_mkNatLit(x_51);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_55 = l_Lean_mkAppB(x_54, x_52, x_53);
x_56 = lean_box(0);
x_57 = 0;
x_58 = 1;
x_59 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_59, 0, x_55);
lean_ctor_set(x_59, 1, x_56);
lean_ctor_set_uint32(x_59, sizeof(void*)*2, x_57);
lean_ctor_set_uint8(x_59, sizeof(void*)*2 + 4, x_58);
x_60 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_60, 0, x_59);
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_47);
return x_61;
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_22);
x_62 = !lean_is_exclusive(x_24);
if (x_62 == 0)
{
return x_24;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_24, 0);
x_64 = lean_ctor_get(x_24, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_24);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_66 = !lean_is_exclusive(x_13);
if (x_66 == 0)
{
return x_13;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_13, 0);
x_68 = lean_ctor_get(x_13, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_13);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
static lean_object* _init_l_BitVec_reduceRotateRight___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("rotateRight", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceRotateRight___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceRotateRight___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceRotateRight___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceRotateRight___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceRotateRight___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceRotateRight___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceRotateRight", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceRotateRight___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceRotateRight), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2;
x_3 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__7;
x_4 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; uint32_t x_46; uint8_t x_47; lean_object* x_48; lean_object* x_49; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_add(x_35, x_36);
lean_dec(x_35);
x_38 = lean_ctor_get(x_22, 1);
lean_inc(x_38);
lean_dec(x_22);
x_39 = lean_ctor_get(x_34, 1);
lean_inc(x_39);
lean_dec(x_34);
x_40 = l_BitVec_append___rarg(x_36, x_38, x_39);
lean_dec(x_39);
lean_dec(x_38);
lean_dec(x_36);
x_41 = l_Lean_mkNatLit(x_37);
x_42 = l_Lean_mkNatLit(x_40);
x_43 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_44 = l_Lean_mkAppB(x_43, x_41, x_42);
x_45 = lean_box(0);
x_46 = 0;
x_47 = 1;
x_48 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_48, 0, x_44);
lean_ctor_set(x_48, 1, x_45);
lean_ctor_set_uint32(x_48, sizeof(void*)*2, x_46);
lean_ctor_set_uint8(x_48, sizeof(void*)*2 + 4, x_47);
x_49 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_49, 0, x_48);
lean_ctor_set(x_24, 0, x_49);
return x_24;
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; uint32_t x_63; uint8_t x_64; lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_50 = lean_ctor_get(x_24, 1);
lean_inc(x_50);
lean_dec(x_24);
x_51 = lean_ctor_get(x_25, 0);
lean_inc(x_51);
lean_dec(x_25);
x_52 = lean_ctor_get(x_22, 0);
lean_inc(x_52);
x_53 = lean_ctor_get(x_51, 0);
lean_inc(x_53);
x_54 = lean_nat_add(x_52, x_53);
lean_dec(x_52);
x_55 = lean_ctor_get(x_22, 1);
lean_inc(x_55);
lean_dec(x_22);
x_56 = lean_ctor_get(x_51, 1);
lean_inc(x_56);
lean_dec(x_51);
x_57 = l_BitVec_append___rarg(x_53, x_55, x_56);
lean_dec(x_56);
lean_dec(x_55);
lean_dec(x_53);
x_58 = l_Lean_mkNatLit(x_54);
x_59 = l_Lean_mkNatLit(x_57);
x_60 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_61 = l_Lean_mkAppB(x_60, x_58, x_59);
x_62 = lean_box(0);
x_63 = 0;
x_64 = 1;
x_65 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_65, 0, x_61);
lean_ctor_set(x_65, 1, x_62);
lean_ctor_set_uint32(x_65, sizeof(void*)*2, x_63);
lean_ctor_set_uint8(x_65, sizeof(void*)*2 + 4, x_64);
x_66 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_66, 0, x_65);
x_67 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_67, 0, x_66);
lean_ctor_set(x_67, 1, x_50);
return x_67;
}
}
}
else
{
uint8_t x_68; 
lean_dec(x_22);
x_68 = !lean_is_exclusive(x_24);
if (x_68 == 0)
{
return x_24;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_24, 0);
x_70 = lean_ctor_get(x_24, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_24);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
}
else
{
uint8_t x_72; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_72 = !lean_is_exclusive(x_13);
if (x_72 == 0)
{
return x_13;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; 
x_73 = lean_ctor_get(x_13, 0);
x_74 = lean_ctor_get(x_13, 1);
lean_inc(x_74);
lean_inc(x_73);
lean_dec(x_13);
x_75 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_75, 0, x_73);
lean_ctor_set(x_75, 1, x_74);
return x_75;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("HAppend", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("hAppend", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAppend___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAppend___closed__1;
x_2 = l_BitVec_reduceAppend___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAppend___closed__3;
x_11 = lean_unsigned_to_nat(6u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAppend___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAppend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceAppend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAppend", 12);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAppend___closed__3;
x_2 = lean_unsigned_to_nat(6u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__6;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__11() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__10;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAppend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__11;
x_4 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2119_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2121_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
x_23 = l_Lean_Expr_appFn_x21(x_22);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_21);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_21, 1);
lean_inc(x_36);
lean_dec(x_21);
x_37 = l_BitVec_ofNat(x_35, x_36);
lean_dec(x_36);
x_38 = l_Lean_mkNatLit(x_35);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_25, 0, x_46);
return x_25;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; uint32_t x_56; uint8_t x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; 
x_47 = lean_ctor_get(x_25, 1);
lean_inc(x_47);
lean_dec(x_25);
x_48 = lean_ctor_get(x_26, 0);
lean_inc(x_48);
lean_dec(x_26);
x_49 = lean_ctor_get(x_21, 1);
lean_inc(x_49);
lean_dec(x_21);
x_50 = l_BitVec_ofNat(x_48, x_49);
lean_dec(x_49);
x_51 = l_Lean_mkNatLit(x_48);
x_52 = l_Lean_mkNatLit(x_50);
x_53 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_54 = l_Lean_mkAppB(x_53, x_51, x_52);
x_55 = lean_box(0);
x_56 = 0;
x_57 = 1;
x_58 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_58, 0, x_54);
lean_ctor_set(x_58, 1, x_55);
lean_ctor_set_uint32(x_58, sizeof(void*)*2, x_56);
lean_ctor_set_uint8(x_58, sizeof(void*)*2 + 4, x_57);
x_59 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_59, 0, x_58);
x_60 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_60, 0, x_59);
lean_ctor_set(x_60, 1, x_47);
return x_60;
}
}
}
else
{
uint8_t x_61; 
lean_dec(x_21);
x_61 = !lean_is_exclusive(x_25);
if (x_61 == 0)
{
return x_25;
}
else
{
lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_62 = lean_ctor_get(x_25, 0);
x_63 = lean_ctor_get(x_25, 1);
lean_inc(x_63);
lean_inc(x_62);
lean_dec(x_25);
x_64 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_64, 0, x_62);
lean_ctor_set(x_64, 1, x_63);
return x_64;
}
}
}
}
else
{
uint8_t x_65; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_65 = !lean_is_exclusive(x_12);
if (x_65 == 0)
{
return x_12;
}
else
{
lean_object* x_66; lean_object* x_67; lean_object* x_68; 
x_66 = lean_ctor_get(x_12, 0);
x_67 = lean_ctor_get(x_12, 1);
lean_inc(x_67);
lean_inc(x_66);
lean_dec(x_12);
x_68 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_67);
return x_68;
}
}
}
}
static lean_object* _init_l_BitVec_reduceCast___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("cast", 4);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceCast___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceCast___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceCast___closed__2;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceCast___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceCast___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceCast___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceCast", 10);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceCast___closed__2;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6;
x_2 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceCast), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2;
x_3 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__8;
x_4 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2268_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2270_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; uint32_t x_26; uint8_t x_27; lean_object* x_28; lean_object* x_29; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 1);
lean_inc(x_23);
lean_dec(x_22);
x_24 = l_Lean_mkNatLit(x_23);
x_25 = lean_box(0);
x_26 = 0;
x_27 = 1;
x_28 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_28, 0, x_24);
lean_ctor_set(x_28, 1, x_25);
lean_ctor_set_uint32(x_28, sizeof(void*)*2, x_26);
lean_ctor_set_uint8(x_28, sizeof(void*)*2 + 4, x_27);
x_29 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_29, 0, x_28);
lean_ctor_set(x_12, 0, x_29);
return x_12;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; uint32_t x_35; uint8_t x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; 
x_30 = lean_ctor_get(x_12, 1);
lean_inc(x_30);
lean_dec(x_12);
x_31 = lean_ctor_get(x_13, 0);
lean_inc(x_31);
lean_dec(x_13);
x_32 = lean_ctor_get(x_31, 1);
lean_inc(x_32);
lean_dec(x_31);
x_33 = l_Lean_mkNatLit(x_32);
x_34 = lean_box(0);
x_35 = 0;
x_36 = 1;
x_37 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_37, 0, x_33);
lean_ctor_set(x_37, 1, x_34);
lean_ctor_set_uint32(x_37, sizeof(void*)*2, x_35);
lean_ctor_set_uint8(x_37, sizeof(void*)*2 + 4, x_36);
x_38 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_38, 0, x_37);
x_39 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_39, 0, x_38);
lean_ctor_set(x_39, 1, x_30);
return x_39;
}
}
}
else
{
uint8_t x_40; 
x_40 = !lean_is_exclusive(x_12);
if (x_40 == 0)
{
return x_12;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_41 = lean_ctor_get(x_12, 0);
x_42 = lean_ctor_get(x_12, 1);
lean_inc(x_42);
lean_inc(x_41);
lean_dec(x_12);
x_43 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_43, 0, x_41);
lean_ctor_set(x_43, 1, x_42);
return x_43;
}
}
}
}
static lean_object* _init_l_BitVec_reduceToNat___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("toNat", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToNat___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceToNat___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceToNat___closed__2;
x_11 = lean_unsigned_to_nat(2u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceToNat___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceToNat___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToNat___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToNat(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceToNat", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToNat___closed__2;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4;
x_2 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToNat___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2;
x_3 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__6;
x_4 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2376_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2378_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__1() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(0u);
x_2 = lean_nat_to_int(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(0u);
x_2 = l_Lean_Level_ofNat(x_1);
return x_2;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__2;
x_3 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_3, 0, x_2);
lean_ctor_set(x_3, 1, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceNeg___closed__3;
x_2 = l_BitVec_reduceToInt___lambda__1___closed__3;
x_3 = l_Lean_Expr_const___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__5() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("Int", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__5;
x_3 = l_Lean_Name_str___override(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__6;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("instNegInt", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___lambda__1___closed__5;
x_2 = l_BitVec_reduceToInt___lambda__1___closed__8;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l_BitVec_reduceToInt___lambda__1___closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = lean_box(0);
x_2 = l_BitVec_reduceToInt___lambda__1___closed__9;
x_3 = l_Lean_Expr_const___override(x_2, x_1);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; uint8_t x_27; lean_object* x_28; uint32_t x_29; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = lean_ctor_get(x_22, 0);
lean_inc(x_23);
x_24 = lean_ctor_get(x_22, 1);
lean_inc(x_24);
lean_dec(x_22);
x_25 = l_BitVec_toInt(x_23, x_24);
lean_dec(x_23);
x_26 = l_BitVec_reduceToInt___lambda__1___closed__1;
x_27 = lean_int_dec_le(x_26, x_25);
x_28 = lean_box(0);
x_29 = 0;
if (x_27 == 0)
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; lean_object* x_38; lean_object* x_39; 
x_30 = lean_int_neg(x_25);
lean_dec(x_25);
x_31 = l_Int_toNat(x_30);
lean_dec(x_30);
x_32 = l_Lean_instToExprInt_mkNat(x_31);
x_33 = l_BitVec_reduceToInt___lambda__1___closed__4;
x_34 = l_BitVec_reduceToInt___lambda__1___closed__7;
x_35 = l_BitVec_reduceToInt___lambda__1___closed__10;
x_36 = l_Lean_mkApp3(x_33, x_34, x_35, x_32);
x_37 = 1;
x_38 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_38, 0, x_36);
lean_ctor_set(x_38, 1, x_28);
lean_ctor_set_uint32(x_38, sizeof(void*)*2, x_29);
lean_ctor_set_uint8(x_38, sizeof(void*)*2 + 4, x_37);
x_39 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_39, 0, x_38);
lean_ctor_set(x_12, 0, x_39);
return x_12;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; lean_object* x_44; 
x_40 = l_Int_toNat(x_25);
lean_dec(x_25);
x_41 = l_Lean_instToExprInt_mkNat(x_40);
x_42 = 1;
x_43 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_43, 0, x_41);
lean_ctor_set(x_43, 1, x_28);
lean_ctor_set_uint32(x_43, sizeof(void*)*2, x_29);
lean_ctor_set_uint8(x_43, sizeof(void*)*2 + 4, x_42);
x_44 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_44, 0, x_43);
lean_ctor_set(x_12, 0, x_44);
return x_12;
}
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; uint8_t x_51; lean_object* x_52; uint32_t x_53; 
x_45 = lean_ctor_get(x_12, 1);
lean_inc(x_45);
lean_dec(x_12);
x_46 = lean_ctor_get(x_13, 0);
lean_inc(x_46);
lean_dec(x_13);
x_47 = lean_ctor_get(x_46, 0);
lean_inc(x_47);
x_48 = lean_ctor_get(x_46, 1);
lean_inc(x_48);
lean_dec(x_46);
x_49 = l_BitVec_toInt(x_47, x_48);
lean_dec(x_47);
x_50 = l_BitVec_reduceToInt___lambda__1___closed__1;
x_51 = lean_int_dec_le(x_50, x_49);
x_52 = lean_box(0);
x_53 = 0;
if (x_51 == 0)
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; uint8_t x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; 
x_54 = lean_int_neg(x_49);
lean_dec(x_49);
x_55 = l_Int_toNat(x_54);
lean_dec(x_54);
x_56 = l_Lean_instToExprInt_mkNat(x_55);
x_57 = l_BitVec_reduceToInt___lambda__1___closed__4;
x_58 = l_BitVec_reduceToInt___lambda__1___closed__7;
x_59 = l_BitVec_reduceToInt___lambda__1___closed__10;
x_60 = l_Lean_mkApp3(x_57, x_58, x_59, x_56);
x_61 = 1;
x_62 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_52);
lean_ctor_set_uint32(x_62, sizeof(void*)*2, x_53);
lean_ctor_set_uint8(x_62, sizeof(void*)*2 + 4, x_61);
x_63 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_63, 0, x_62);
x_64 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_64, 0, x_63);
lean_ctor_set(x_64, 1, x_45);
return x_64;
}
else
{
lean_object* x_65; lean_object* x_66; uint8_t x_67; lean_object* x_68; lean_object* x_69; lean_object* x_70; 
x_65 = l_Int_toNat(x_49);
lean_dec(x_49);
x_66 = l_Lean_instToExprInt_mkNat(x_65);
x_67 = 1;
x_68 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_68, 0, x_66);
lean_ctor_set(x_68, 1, x_52);
lean_ctor_set_uint32(x_68, sizeof(void*)*2, x_53);
lean_ctor_set_uint8(x_68, sizeof(void*)*2 + 4, x_67);
x_69 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_69, 0, x_68);
x_70 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_70, 0, x_69);
lean_ctor_set(x_70, 1, x_45);
return x_70;
}
}
}
}
else
{
uint8_t x_71; 
x_71 = !lean_is_exclusive(x_12);
if (x_71 == 0)
{
return x_12;
}
else
{
lean_object* x_72; lean_object* x_73; lean_object* x_74; 
x_72 = lean_ctor_get(x_12, 0);
x_73 = lean_ctor_get(x_12, 1);
lean_inc(x_73);
lean_inc(x_72);
lean_dec(x_12);
x_74 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_74, 0, x_72);
lean_ctor_set(x_74, 1, x_73);
return x_74;
}
}
}
}
static lean_object* _init_l_BitVec_reduceToInt___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("toInt", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceToInt___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceToInt___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceToInt___closed__2;
x_11 = lean_unsigned_to_nat(2u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceToInt___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceToInt___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceToInt___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceToInt(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceToInt", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceToInt___closed__2;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4;
x_2 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceToInt___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2;
x_3 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__6;
x_4 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2484_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2486_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_Lean_Meta_getNatValue_x3f(x_12, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getIntValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint32_t x_41; uint8_t x_42; lean_object* x_43; lean_object* x_44; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = l_BitVec_ofInt(x_22, x_34);
lean_dec(x_34);
x_36 = l_Lean_mkNatLit(x_22);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_box(0);
x_41 = 0;
x_42 = 1;
x_43 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_43, 0, x_39);
lean_ctor_set(x_43, 1, x_40);
lean_ctor_set_uint32(x_43, sizeof(void*)*2, x_41);
lean_ctor_set_uint8(x_43, sizeof(void*)*2 + 4, x_42);
x_44 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_44, 0, x_43);
lean_ctor_set(x_24, 0, x_44);
return x_24;
}
else
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; uint32_t x_53; uint8_t x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; 
x_45 = lean_ctor_get(x_24, 1);
lean_inc(x_45);
lean_dec(x_24);
x_46 = lean_ctor_get(x_25, 0);
lean_inc(x_46);
lean_dec(x_25);
x_47 = l_BitVec_ofInt(x_22, x_46);
lean_dec(x_46);
x_48 = l_Lean_mkNatLit(x_22);
x_49 = l_Lean_mkNatLit(x_47);
x_50 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_51 = l_Lean_mkAppB(x_50, x_48, x_49);
x_52 = lean_box(0);
x_53 = 0;
x_54 = 1;
x_55 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_55, 0, x_51);
lean_ctor_set(x_55, 1, x_52);
lean_ctor_set_uint32(x_55, sizeof(void*)*2, x_53);
lean_ctor_set_uint8(x_55, sizeof(void*)*2 + 4, x_54);
x_56 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_56, 0, x_55);
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_45);
return x_57;
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceOfInt___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ofInt", 5);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceOfInt___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceOfInt___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceOfInt___closed__2;
x_11 = lean_unsigned_to_nat(2u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceOfInt___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfInt___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceOfInt___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceOfInt", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceOfInt___closed__2;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4;
x_2 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfInt), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__6;
x_4 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2633_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2635_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; lean_object* x_13; lean_object* x_14; lean_object* x_15; lean_object* x_16; uint32_t x_17; uint8_t x_18; lean_object* x_19; lean_object* x_20; lean_object* x_21; 
x_12 = l_Lean_mkNatLit(x_1);
x_13 = l_Lean_mkNatLit(x_2);
x_14 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_15 = l_Lean_mkAppB(x_14, x_12, x_13);
x_16 = lean_box(0);
x_17 = 0;
x_18 = 1;
x_19 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_19, 0, x_15);
lean_ctor_set(x_19, 1, x_16);
lean_ctor_set_uint32(x_19, sizeof(void*)*2, x_17);
lean_ctor_set_uint8(x_19, sizeof(void*)*2 + 4, x_18);
x_20 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_20, 0, x_19);
x_21 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_21, 0, x_20);
lean_ctor_set(x_21, 1, x_11);
return x_21;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__2(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_dec(x_2);
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_Lean_Meta_getNatValue_x3f(x_12, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = l_BitVec_ofNat(x_22, x_35);
x_37 = lean_nat_dec_eq(x_36, x_35);
lean_dec(x_35);
if (x_37 == 0)
{
lean_object* x_38; lean_object* x_39; 
lean_free_object(x_24);
x_38 = lean_box(0);
x_39 = l_BitVec_reduceOfNat___lambda__1(x_22, x_36, x_38, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_39;
}
else
{
lean_object* x_40; 
lean_dec(x_36);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_40);
return x_24;
}
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; uint8_t x_44; 
x_41 = lean_ctor_get(x_24, 1);
lean_inc(x_41);
lean_dec(x_24);
x_42 = lean_ctor_get(x_25, 0);
lean_inc(x_42);
lean_dec(x_25);
x_43 = l_BitVec_ofNat(x_22, x_42);
x_44 = lean_nat_dec_eq(x_43, x_42);
lean_dec(x_42);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; 
x_45 = lean_box(0);
x_46 = l_BitVec_reduceOfNat___lambda__1(x_22, x_43, x_45, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_41);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_46;
}
else
{
lean_object* x_47; lean_object* x_48; 
lean_dec(x_43);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_47 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_48 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_48, 0, x_47);
lean_ctor_set(x_48, 1, x_41);
return x_48;
}
}
}
}
else
{
uint8_t x_49; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
x_49 = !lean_is_exclusive(x_24);
if (x_49 == 0)
{
return x_24;
}
else
{
lean_object* x_50; lean_object* x_51; lean_object* x_52; 
x_50 = lean_ctor_get(x_24, 0);
x_51 = lean_ctor_get(x_24, 1);
lean_inc(x_51);
lean_inc(x_50);
lean_dec(x_24);
x_52 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_52, 0, x_50);
lean_ctor_set(x_52, 1, x_51);
return x_52;
}
}
}
}
else
{
uint8_t x_53; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_1);
x_53 = !lean_is_exclusive(x_13);
if (x_53 == 0)
{
return x_13;
}
else
{
lean_object* x_54; lean_object* x_55; lean_object* x_56; 
x_54 = lean_ctor_get(x_13, 0);
x_55 = lean_ctor_get(x_13, 1);
lean_inc(x_55);
lean_inc(x_54);
lean_dec(x_13);
x_56 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_56, 0, x_54);
lean_ctor_set(x_56, 1, x_55);
return x_56;
}
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceUnary___lambda__1___closed__4;
x_11 = lean_unsigned_to_nat(2u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceOfNat___lambda__2(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceOfNat___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10, lean_object* x_11) {
_start:
{
lean_object* x_12; 
x_12 = l_BitVec_reduceOfNat___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10, x_11);
lean_dec(x_10);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
return x_12;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceOfNat", 11);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__4;
x_2 = lean_unsigned_to_nat(2u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4;
x_2 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceOfNat), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2;
x_3 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__6;
x_4 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2831_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2833_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_lt(x_40, x_41);
lean_dec(x_41);
lean_dec(x_40);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_lt(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceLT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("LT", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLT___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("lt", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLT___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLT___closed__1;
x_2 = l_BitVec_reduceLT___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceLT___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceLT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceLT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceLT", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLT___closed__3;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(6u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__4;
x_2 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__5;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__10() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__9;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceLT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__10;
x_4 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2874_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2876_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_le(x_40, x_41);
lean_dec(x_41);
lean_dec(x_40);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_le(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceLE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("LE", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLE___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("le", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceLE___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLE___closed__1;
x_2 = l_BitVec_reduceLE___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceLE___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceLE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceLE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceLE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceLE", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceLE___closed__3;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__4;
x_2 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__4;
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__9() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__8;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceLE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__9;
x_4 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2917_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2919_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_lt(x_41, x_40);
lean_dec(x_40);
lean_dec(x_41);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_lt(x_52, x_51);
lean_dec(x_51);
lean_dec(x_52);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("GT", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGT___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("gt", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGT___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGT___closed__1;
x_2 = l_BitVec_reduceGT___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGT___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGT", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__10;
x_4 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2960_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2962_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; uint8_t x_38; 
x_33 = lean_ctor_get(x_24, 1);
x_34 = lean_ctor_get(x_24, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_25, 0);
lean_inc(x_35);
lean_dec(x_25);
x_36 = lean_ctor_get(x_22, 0);
lean_inc(x_36);
x_37 = lean_ctor_get(x_35, 0);
lean_inc(x_37);
x_38 = lean_nat_dec_eq(x_36, x_37);
lean_dec(x_37);
lean_dec(x_36);
if (x_38 == 0)
{
lean_object* x_39; 
lean_dec(x_35);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_39 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_39);
return x_24;
}
else
{
lean_object* x_40; lean_object* x_41; uint8_t x_42; lean_object* x_43; 
lean_free_object(x_24);
x_40 = lean_ctor_get(x_22, 1);
lean_inc(x_40);
lean_dec(x_22);
x_41 = lean_ctor_get(x_35, 1);
lean_inc(x_41);
lean_dec(x_35);
x_42 = lean_nat_dec_le(x_41, x_40);
lean_dec(x_40);
lean_dec(x_41);
x_43 = l_Lean_Meta_Simp_evalPropStep(x_1, x_42, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_33);
return x_43;
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; lean_object* x_54; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_le(x_52, x_51);
lean_dec(x_51);
lean_dec(x_52);
x_54 = l_Lean_Meta_Simp_evalPropStep(x_1, x_53, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_44);
return x_54;
}
}
}
}
else
{
uint8_t x_55; 
lean_dec(x_22);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_55 = !lean_is_exclusive(x_24);
if (x_55 == 0)
{
return x_24;
}
else
{
lean_object* x_56; lean_object* x_57; lean_object* x_58; 
x_56 = lean_ctor_get(x_24, 0);
x_57 = lean_ctor_get(x_24, 1);
lean_inc(x_57);
lean_inc(x_56);
lean_dec(x_24);
x_58 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_58, 0, x_56);
lean_ctor_set(x_58, 1, x_57);
return x_58;
}
}
}
}
else
{
uint8_t x_59; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_59 = !lean_is_exclusive(x_13);
if (x_59 == 0)
{
return x_13;
}
else
{
lean_object* x_60; lean_object* x_61; lean_object* x_62; 
x_60 = lean_ctor_get(x_13, 0);
x_61 = lean_ctor_get(x_13, 1);
lean_inc(x_61);
lean_inc(x_60);
lean_dec(x_13);
x_62 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_62, 0, x_60);
lean_ctor_set(x_62, 1, x_61);
return x_62;
}
}
}
}
static lean_object* _init_l_BitVec_reduceGE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("GE", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGE___closed__2() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ge", 2);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceGE___closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceGE___closed__1;
x_2 = l_BitVec_reduceGE___closed__2;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceGE___closed__3;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceGE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceGE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceGE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceGE", 8);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceGE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2;
x_3 = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__9;
x_4 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3003_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3005_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
lean_dec(x_35);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_dec_lt(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_lt(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceULT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ult", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceULT___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceULT___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceULT___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceULT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceULT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceULT", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceULT___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceULT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2;
x_3 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__7;
x_4 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3026_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3028_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
lean_dec(x_35);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = lean_nat_dec_le(x_39, x_40);
lean_dec(x_40);
lean_dec(x_39);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
lean_dec(x_46);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = lean_nat_dec_le(x_51, x_52);
lean_dec(x_52);
lean_dec(x_51);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceULE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("ule", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceULE___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceULE___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceULE___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceULE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceULE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceULE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceULE", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceULE___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceULE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2;
x_3 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__7;
x_4 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3049_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3051_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_slt(x_35, x_39, x_40);
lean_dec(x_35);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_46);
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = l_BitVec_slt(x_46, x_51, x_52);
lean_dec(x_46);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSLT___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("slt", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSLT___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSLT___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSLT___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSLT___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLT___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSLT___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSLT", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSLT___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSLT), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3072_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3074_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_BitVec_fromExpr_x3f(x_23, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_21);
lean_dec(x_23);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_34, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_eq(x_35, x_36);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_34);
lean_dec(x_22);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_38);
return x_24;
}
else
{
lean_object* x_39; lean_object* x_40; uint8_t x_41; 
x_39 = lean_ctor_get(x_22, 1);
lean_inc(x_39);
lean_dec(x_22);
x_40 = lean_ctor_get(x_34, 1);
lean_inc(x_40);
lean_dec(x_34);
x_41 = l_BitVec_sle(x_35, x_39, x_40);
lean_dec(x_35);
if (x_41 == 0)
{
lean_object* x_42; 
x_42 = l_BitVec_reduceGetBit___lambda__1___closed__6;
lean_ctor_set(x_24, 0, x_42);
return x_24;
}
else
{
lean_object* x_43; 
x_43 = l_BitVec_reduceGetBit___lambda__1___closed__11;
lean_ctor_set(x_24, 0, x_43);
return x_24;
}
}
}
else
{
lean_object* x_44; lean_object* x_45; lean_object* x_46; lean_object* x_47; uint8_t x_48; 
x_44 = lean_ctor_get(x_24, 1);
lean_inc(x_44);
lean_dec(x_24);
x_45 = lean_ctor_get(x_25, 0);
lean_inc(x_45);
lean_dec(x_25);
x_46 = lean_ctor_get(x_22, 0);
lean_inc(x_46);
x_47 = lean_ctor_get(x_45, 0);
lean_inc(x_47);
x_48 = lean_nat_dec_eq(x_46, x_47);
lean_dec(x_47);
if (x_48 == 0)
{
lean_object* x_49; lean_object* x_50; 
lean_dec(x_46);
lean_dec(x_45);
lean_dec(x_22);
x_49 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_50 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_50, 0, x_49);
lean_ctor_set(x_50, 1, x_44);
return x_50;
}
else
{
lean_object* x_51; lean_object* x_52; uint8_t x_53; 
x_51 = lean_ctor_get(x_22, 1);
lean_inc(x_51);
lean_dec(x_22);
x_52 = lean_ctor_get(x_45, 1);
lean_inc(x_52);
lean_dec(x_45);
x_53 = l_BitVec_sle(x_46, x_51, x_52);
lean_dec(x_46);
if (x_53 == 0)
{
lean_object* x_54; lean_object* x_55; 
x_54 = l_BitVec_reduceGetBit___lambda__1___closed__6;
x_55 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_55, 0, x_54);
lean_ctor_set(x_55, 1, x_44);
return x_55;
}
else
{
lean_object* x_56; lean_object* x_57; 
x_56 = l_BitVec_reduceGetBit___lambda__1___closed__11;
x_57 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_57, 1, x_44);
return x_57;
}
}
}
}
}
else
{
uint8_t x_58; 
lean_dec(x_22);
x_58 = !lean_is_exclusive(x_24);
if (x_58 == 0)
{
return x_24;
}
else
{
lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_59 = lean_ctor_get(x_24, 0);
x_60 = lean_ctor_get(x_24, 1);
lean_inc(x_60);
lean_inc(x_59);
lean_dec(x_24);
x_61 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_61, 0, x_59);
lean_ctor_set(x_61, 1, x_60);
return x_61;
}
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_62 = !lean_is_exclusive(x_13);
if (x_62 == 0)
{
return x_13;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_13, 0);
x_64 = lean_ctor_get(x_13, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_13);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSLE___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("sle", 3);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSLE___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSLE___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSLE___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSLE___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSLE___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSLE___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSLE", 9);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSLE___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSLE), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3095_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3097_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
x_23 = l_Lean_Expr_appFn_x21(x_22);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_21);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
uint8_t x_33; 
x_33 = !lean_is_exclusive(x_25);
if (x_33 == 0)
{
lean_object* x_34; lean_object* x_35; lean_object* x_36; uint8_t x_37; 
x_34 = lean_ctor_get(x_25, 0);
lean_dec(x_34);
x_35 = lean_ctor_get(x_26, 0);
lean_inc(x_35);
lean_dec(x_26);
x_36 = lean_ctor_get(x_21, 0);
lean_inc(x_36);
x_37 = lean_nat_dec_le(x_36, x_35);
lean_dec(x_36);
if (x_37 == 0)
{
lean_object* x_38; 
lean_dec(x_35);
lean_dec(x_21);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_38);
return x_25;
}
else
{
lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; lean_object* x_44; uint32_t x_45; uint8_t x_46; lean_object* x_47; lean_object* x_48; 
x_39 = lean_ctor_get(x_21, 1);
lean_inc(x_39);
lean_dec(x_21);
x_40 = l_Lean_mkNatLit(x_35);
x_41 = l_Lean_mkNatLit(x_39);
x_42 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_43 = l_Lean_mkAppB(x_42, x_40, x_41);
x_44 = lean_box(0);
x_45 = 0;
x_46 = 1;
x_47 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_47, 0, x_43);
lean_ctor_set(x_47, 1, x_44);
lean_ctor_set_uint32(x_47, sizeof(void*)*2, x_45);
lean_ctor_set_uint8(x_47, sizeof(void*)*2 + 4, x_46);
x_48 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_48, 0, x_47);
lean_ctor_set(x_25, 0, x_48);
return x_25;
}
}
else
{
lean_object* x_49; lean_object* x_50; lean_object* x_51; uint8_t x_52; 
x_49 = lean_ctor_get(x_25, 1);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_26, 0);
lean_inc(x_50);
lean_dec(x_26);
x_51 = lean_ctor_get(x_21, 0);
lean_inc(x_51);
x_52 = lean_nat_dec_le(x_51, x_50);
lean_dec(x_51);
if (x_52 == 0)
{
lean_object* x_53; lean_object* x_54; 
lean_dec(x_50);
lean_dec(x_21);
x_53 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_54 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_54, 0, x_53);
lean_ctor_set(x_54, 1, x_49);
return x_54;
}
else
{
lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; lean_object* x_59; lean_object* x_60; uint32_t x_61; uint8_t x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_55 = lean_ctor_get(x_21, 1);
lean_inc(x_55);
lean_dec(x_21);
x_56 = l_Lean_mkNatLit(x_50);
x_57 = l_Lean_mkNatLit(x_55);
x_58 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_59 = l_Lean_mkAppB(x_58, x_56, x_57);
x_60 = lean_box(0);
x_61 = 0;
x_62 = 1;
x_63 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_63, 0, x_59);
lean_ctor_set(x_63, 1, x_60);
lean_ctor_set_uint32(x_63, sizeof(void*)*2, x_61);
lean_ctor_set_uint8(x_63, sizeof(void*)*2 + 4, x_62);
x_64 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_64, 0, x_63);
x_65 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_65, 0, x_64);
lean_ctor_set(x_65, 1, x_49);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_21);
x_66 = !lean_is_exclusive(x_25);
if (x_66 == 0)
{
return x_25;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_25, 0);
x_68 = lean_ctor_get(x_25, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_25);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
else
{
uint8_t x_70; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_70 = !lean_is_exclusive(x_12);
if (x_70 == 0)
{
return x_12;
}
else
{
lean_object* x_71; lean_object* x_72; lean_object* x_73; 
x_71 = lean_ctor_get(x_12, 0);
x_72 = lean_ctor_get(x_12, 1);
lean_inc(x_72);
lean_inc(x_71);
lean_dec(x_12);
x_73 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_73, 0, x_71);
lean_ctor_set(x_73, 1, x_72);
return x_73;
}
}
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend_x27___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("zeroExtend'", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend_x27___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceZeroExtend_x27___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceZeroExtend_x27___closed__2;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceZeroExtend_x27___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend_x27___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceZeroExtend_x27___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceZeroExtend'", 17);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceZeroExtend_x27___closed__2;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceZeroExtend_x27), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__8;
x_4 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3268_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3270_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; lean_object* x_13; 
lean_inc(x_1);
x_11 = l_Lean_Expr_appFn_x21(x_1);
x_12 = l_Lean_Expr_appArg_x21(x_11);
lean_dec(x_11);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_13 = l_BitVec_fromExpr_x3f(x_12, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_12);
if (lean_obj_tag(x_13) == 0)
{
lean_object* x_14; 
x_14 = lean_ctor_get(x_13, 0);
lean_inc(x_14);
if (lean_obj_tag(x_14) == 0)
{
uint8_t x_15; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_15 = !lean_is_exclusive(x_13);
if (x_15 == 0)
{
lean_object* x_16; lean_object* x_17; 
x_16 = lean_ctor_get(x_13, 0);
lean_dec(x_16);
x_17 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_13, 0, x_17);
return x_13;
}
else
{
lean_object* x_18; lean_object* x_19; lean_object* x_20; 
x_18 = lean_ctor_get(x_13, 1);
lean_inc(x_18);
lean_dec(x_13);
x_19 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_20 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_20, 0, x_19);
lean_ctor_set(x_20, 1, x_18);
return x_20;
}
}
else
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_21 = lean_ctor_get(x_13, 1);
lean_inc(x_21);
lean_dec(x_13);
x_22 = lean_ctor_get(x_14, 0);
lean_inc(x_22);
lean_dec(x_14);
x_23 = l_Lean_Expr_appArg_x21(x_1);
lean_dec(x_1);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_21);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_22);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; uint32_t x_44; uint8_t x_45; lean_object* x_46; lean_object* x_47; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_22, 0);
lean_inc(x_35);
x_36 = lean_nat_add(x_35, x_34);
lean_dec(x_35);
x_37 = lean_ctor_get(x_22, 1);
lean_inc(x_37);
lean_dec(x_22);
x_38 = lean_nat_shiftl(x_37, x_34);
lean_dec(x_34);
lean_dec(x_37);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkNatLit(x_38);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_42 = l_Lean_mkAppB(x_41, x_39, x_40);
x_43 = lean_box(0);
x_44 = 0;
x_45 = 1;
x_46 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_46, 0, x_42);
lean_ctor_set(x_46, 1, x_43);
lean_ctor_set_uint32(x_46, sizeof(void*)*2, x_44);
lean_ctor_set_uint8(x_46, sizeof(void*)*2 + 4, x_45);
x_47 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_47, 0, x_46);
lean_ctor_set(x_24, 0, x_47);
return x_24;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; uint32_t x_59; uint8_t x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_48 = lean_ctor_get(x_24, 1);
lean_inc(x_48);
lean_dec(x_24);
x_49 = lean_ctor_get(x_25, 0);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_22, 0);
lean_inc(x_50);
x_51 = lean_nat_add(x_50, x_49);
lean_dec(x_50);
x_52 = lean_ctor_get(x_22, 1);
lean_inc(x_52);
lean_dec(x_22);
x_53 = lean_nat_shiftl(x_52, x_49);
lean_dec(x_49);
lean_dec(x_52);
x_54 = l_Lean_mkNatLit(x_51);
x_55 = l_Lean_mkNatLit(x_53);
x_56 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_57 = l_Lean_mkAppB(x_56, x_54, x_55);
x_58 = lean_box(0);
x_59 = 0;
x_60 = 1;
x_61 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_61, 0, x_57);
lean_ctor_set(x_61, 1, x_58);
lean_ctor_set_uint32(x_61, sizeof(void*)*2, x_59);
lean_ctor_set_uint8(x_61, sizeof(void*)*2 + 4, x_60);
x_62 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_63, 0, x_62);
lean_ctor_set(x_63, 1, x_48);
return x_63;
}
}
}
else
{
uint8_t x_64; 
lean_dec(x_22);
x_64 = !lean_is_exclusive(x_24);
if (x_64 == 0)
{
return x_24;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_65 = lean_ctor_get(x_24, 0);
x_66 = lean_ctor_get(x_24, 1);
lean_inc(x_66);
lean_inc(x_65);
lean_dec(x_24);
x_67 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_67, 0, x_65);
lean_ctor_set(x_67, 1, x_66);
return x_67;
}
}
}
}
else
{
uint8_t x_68; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_68 = !lean_is_exclusive(x_13);
if (x_68 == 0)
{
return x_13;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_13, 0);
x_70 = lean_ctor_get(x_13, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_13);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("shiftLeftZeroExtend", 19);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceShiftLeftZeroExtend___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceShiftLeftZeroExtend___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceShiftLeftZeroExtend___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceShiftLeftZeroExtend___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceShiftLeftZeroExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceShiftLeftZeroExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceShiftLeftZeroExtend", 25);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceShiftLeftZeroExtend___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceShiftLeftZeroExtend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2;
x_3 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__7;
x_4 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3416_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3418_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
lean_inc(x_22);
x_23 = l_Lean_Expr_appFn_x21(x_22);
x_24 = l_Lean_Expr_appArg_x21(x_23);
lean_dec(x_23);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_25 = l_Lean_Meta_getNatValue_x3f(x_24, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_25) == 0)
{
lean_object* x_26; 
x_26 = lean_ctor_get(x_25, 0);
lean_inc(x_26);
if (lean_obj_tag(x_26) == 0)
{
uint8_t x_27; 
lean_dec(x_22);
lean_dec(x_21);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
x_27 = !lean_is_exclusive(x_25);
if (x_27 == 0)
{
lean_object* x_28; lean_object* x_29; 
x_28 = lean_ctor_get(x_25, 0);
lean_dec(x_28);
x_29 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_25, 0, x_29);
return x_25;
}
else
{
lean_object* x_30; lean_object* x_31; lean_object* x_32; 
x_30 = lean_ctor_get(x_25, 1);
lean_inc(x_30);
lean_dec(x_25);
x_31 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_32 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_32, 1, x_30);
return x_32;
}
}
else
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; 
x_33 = lean_ctor_get(x_25, 1);
lean_inc(x_33);
lean_dec(x_25);
x_34 = lean_ctor_get(x_26, 0);
lean_inc(x_34);
lean_dec(x_26);
x_35 = l_Lean_Expr_appArg_x21(x_22);
lean_dec(x_22);
x_36 = l_Lean_Meta_getNatValue_x3f(x_35, x_6, x_7, x_8, x_9, x_33);
if (lean_obj_tag(x_36) == 0)
{
lean_object* x_37; 
x_37 = lean_ctor_get(x_36, 0);
lean_inc(x_37);
if (lean_obj_tag(x_37) == 0)
{
uint8_t x_38; 
lean_dec(x_34);
lean_dec(x_21);
x_38 = !lean_is_exclusive(x_36);
if (x_38 == 0)
{
lean_object* x_39; lean_object* x_40; 
x_39 = lean_ctor_get(x_36, 0);
lean_dec(x_39);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_36, 0, x_40);
return x_36;
}
else
{
lean_object* x_41; lean_object* x_42; lean_object* x_43; 
x_41 = lean_ctor_get(x_36, 1);
lean_inc(x_41);
lean_dec(x_36);
x_42 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_43 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_43, 0, x_42);
lean_ctor_set(x_43, 1, x_41);
return x_43;
}
}
else
{
uint8_t x_44; 
x_44 = !lean_is_exclusive(x_36);
if (x_44 == 0)
{
lean_object* x_45; lean_object* x_46; lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; uint32_t x_54; uint8_t x_55; lean_object* x_56; lean_object* x_57; 
x_45 = lean_ctor_get(x_36, 0);
lean_dec(x_45);
x_46 = lean_ctor_get(x_37, 0);
lean_inc(x_46);
lean_dec(x_37);
x_47 = lean_ctor_get(x_21, 1);
lean_inc(x_47);
lean_dec(x_21);
x_48 = l_BitVec_extractLsb_x27___rarg(x_34, x_46, x_47);
lean_dec(x_47);
lean_dec(x_34);
x_49 = l_Lean_mkNatLit(x_46);
x_50 = l_Lean_mkNatLit(x_48);
x_51 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_52 = l_Lean_mkAppB(x_51, x_49, x_50);
x_53 = lean_box(0);
x_54 = 0;
x_55 = 1;
x_56 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_56, 0, x_52);
lean_ctor_set(x_56, 1, x_53);
lean_ctor_set_uint32(x_56, sizeof(void*)*2, x_54);
lean_ctor_set_uint8(x_56, sizeof(void*)*2 + 4, x_55);
x_57 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_57, 0, x_56);
lean_ctor_set(x_36, 0, x_57);
return x_36;
}
else
{
lean_object* x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; lean_object* x_64; lean_object* x_65; lean_object* x_66; uint32_t x_67; uint8_t x_68; lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_58 = lean_ctor_get(x_36, 1);
lean_inc(x_58);
lean_dec(x_36);
x_59 = lean_ctor_get(x_37, 0);
lean_inc(x_59);
lean_dec(x_37);
x_60 = lean_ctor_get(x_21, 1);
lean_inc(x_60);
lean_dec(x_21);
x_61 = l_BitVec_extractLsb_x27___rarg(x_34, x_59, x_60);
lean_dec(x_60);
lean_dec(x_34);
x_62 = l_Lean_mkNatLit(x_59);
x_63 = l_Lean_mkNatLit(x_61);
x_64 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_65 = l_Lean_mkAppB(x_64, x_62, x_63);
x_66 = lean_box(0);
x_67 = 0;
x_68 = 1;
x_69 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_69, 0, x_65);
lean_ctor_set(x_69, 1, x_66);
lean_ctor_set_uint32(x_69, sizeof(void*)*2, x_67);
lean_ctor_set_uint8(x_69, sizeof(void*)*2 + 4, x_68);
x_70 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_70, 0, x_69);
x_71 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_71, 0, x_70);
lean_ctor_set(x_71, 1, x_58);
return x_71;
}
}
}
else
{
uint8_t x_72; 
lean_dec(x_34);
lean_dec(x_21);
x_72 = !lean_is_exclusive(x_36);
if (x_72 == 0)
{
return x_36;
}
else
{
lean_object* x_73; lean_object* x_74; lean_object* x_75; 
x_73 = lean_ctor_get(x_36, 0);
x_74 = lean_ctor_get(x_36, 1);
lean_inc(x_74);
lean_inc(x_73);
lean_dec(x_36);
x_75 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_75, 0, x_73);
lean_ctor_set(x_75, 1, x_74);
return x_75;
}
}
}
}
else
{
uint8_t x_76; 
lean_dec(x_22);
lean_dec(x_21);
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
x_76 = !lean_is_exclusive(x_25);
if (x_76 == 0)
{
return x_25;
}
else
{
lean_object* x_77; lean_object* x_78; lean_object* x_79; 
x_77 = lean_ctor_get(x_25, 0);
x_78 = lean_ctor_get(x_25, 1);
lean_inc(x_78);
lean_inc(x_77);
lean_dec(x_25);
x_79 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_79, 0, x_77);
lean_ctor_set(x_79, 1, x_78);
return x_79;
}
}
}
}
else
{
uint8_t x_80; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_80 = !lean_is_exclusive(x_12);
if (x_80 == 0)
{
return x_12;
}
else
{
lean_object* x_81; lean_object* x_82; lean_object* x_83; 
x_81 = lean_ctor_get(x_12, 0);
x_82 = lean_ctor_get(x_12, 1);
lean_inc(x_82);
lean_inc(x_81);
lean_dec(x_12);
x_83 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_83, 0, x_81);
lean_ctor_set(x_83, 1, x_82);
return x_83;
}
}
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("extractLsb'", 11);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceExtracLsb_x27___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceExtracLsb_x27___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceExtracLsb_x27___closed__2;
x_11 = lean_unsigned_to_nat(4u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceExtracLsb_x27___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceExtracLsb_x27___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceExtracLsb_x27___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceExtracLsb'", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceExtracLsb_x27___closed__2;
x_2 = lean_unsigned_to_nat(4u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6;
x_2 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__8() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__7;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceExtracLsb_x27), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2;
x_3 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__8;
x_4 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3602_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3604_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
x_23 = l_Lean_Expr_appArg_x21(x_22);
lean_dec(x_22);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_21);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; lean_object* x_43; uint32_t x_44; uint8_t x_45; lean_object* x_46; lean_object* x_47; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_21, 0);
lean_inc(x_35);
x_36 = lean_nat_mul(x_35, x_34);
x_37 = lean_ctor_get(x_21, 1);
lean_inc(x_37);
lean_dec(x_21);
x_38 = l_BitVec_replicate(x_35, x_34, x_37);
lean_dec(x_37);
lean_dec(x_34);
lean_dec(x_35);
x_39 = l_Lean_mkNatLit(x_36);
x_40 = l_Lean_mkNatLit(x_38);
x_41 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_42 = l_Lean_mkAppB(x_41, x_39, x_40);
x_43 = lean_box(0);
x_44 = 0;
x_45 = 1;
x_46 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_46, 0, x_42);
lean_ctor_set(x_46, 1, x_43);
lean_ctor_set_uint32(x_46, sizeof(void*)*2, x_44);
lean_ctor_set_uint8(x_46, sizeof(void*)*2 + 4, x_45);
x_47 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_47, 0, x_46);
lean_ctor_set(x_24, 0, x_47);
return x_24;
}
else
{
lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; lean_object* x_57; lean_object* x_58; uint32_t x_59; uint8_t x_60; lean_object* x_61; lean_object* x_62; lean_object* x_63; 
x_48 = lean_ctor_get(x_24, 1);
lean_inc(x_48);
lean_dec(x_24);
x_49 = lean_ctor_get(x_25, 0);
lean_inc(x_49);
lean_dec(x_25);
x_50 = lean_ctor_get(x_21, 0);
lean_inc(x_50);
x_51 = lean_nat_mul(x_50, x_49);
x_52 = lean_ctor_get(x_21, 1);
lean_inc(x_52);
lean_dec(x_21);
x_53 = l_BitVec_replicate(x_50, x_49, x_52);
lean_dec(x_52);
lean_dec(x_49);
lean_dec(x_50);
x_54 = l_Lean_mkNatLit(x_51);
x_55 = l_Lean_mkNatLit(x_53);
x_56 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_57 = l_Lean_mkAppB(x_56, x_54, x_55);
x_58 = lean_box(0);
x_59 = 0;
x_60 = 1;
x_61 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_61, 0, x_57);
lean_ctor_set(x_61, 1, x_58);
lean_ctor_set_uint32(x_61, sizeof(void*)*2, x_59);
lean_ctor_set_uint8(x_61, sizeof(void*)*2 + 4, x_60);
x_62 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_62, 0, x_61);
x_63 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_63, 0, x_62);
lean_ctor_set(x_63, 1, x_48);
return x_63;
}
}
}
else
{
uint8_t x_64; 
lean_dec(x_21);
x_64 = !lean_is_exclusive(x_24);
if (x_64 == 0)
{
return x_24;
}
else
{
lean_object* x_65; lean_object* x_66; lean_object* x_67; 
x_65 = lean_ctor_get(x_24, 0);
x_66 = lean_ctor_get(x_24, 1);
lean_inc(x_66);
lean_inc(x_65);
lean_dec(x_24);
x_67 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_67, 0, x_65);
lean_ctor_set(x_67, 1, x_66);
return x_67;
}
}
}
}
else
{
uint8_t x_68; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_68 = !lean_is_exclusive(x_12);
if (x_68 == 0)
{
return x_12;
}
else
{
lean_object* x_69; lean_object* x_70; lean_object* x_71; 
x_69 = lean_ctor_get(x_12, 0);
x_70 = lean_ctor_get(x_12, 1);
lean_inc(x_70);
lean_inc(x_69);
lean_dec(x_12);
x_71 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_71, 0, x_69);
lean_ctor_set(x_71, 1, x_70);
return x_71;
}
}
}
}
static lean_object* _init_l_BitVec_reduceReplicate___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("replicate", 9);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceReplicate___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceReplicate___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceReplicate___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceReplicate___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceReplicate___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceReplicate___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceReplicate", 15);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceReplicate___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceReplicate), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2;
x_3 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__7;
x_4 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3750_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3752_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
x_23 = l_Lean_Expr_appArg_x21(x_22);
lean_dec(x_22);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_21);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_21, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_21, 1);
lean_inc(x_36);
lean_dec(x_21);
x_37 = l_BitVec_zeroExtend(x_35, x_34, x_36);
lean_dec(x_36);
lean_dec(x_35);
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; uint32_t x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_21, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_21, 1);
lean_inc(x_50);
lean_dec(x_21);
x_51 = l_BitVec_zeroExtend(x_49, x_48, x_50);
lean_dec(x_50);
lean_dec(x_49);
x_52 = l_Lean_mkNatLit(x_48);
x_53 = l_Lean_mkNatLit(x_51);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_55 = l_Lean_mkAppB(x_54, x_52, x_53);
x_56 = lean_box(0);
x_57 = 0;
x_58 = 1;
x_59 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_59, 0, x_55);
lean_ctor_set(x_59, 1, x_56);
lean_ctor_set_uint32(x_59, sizeof(void*)*2, x_57);
lean_ctor_set_uint8(x_59, sizeof(void*)*2 + 4, x_58);
x_60 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_60, 0, x_59);
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_47);
return x_61;
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_21);
x_62 = !lean_is_exclusive(x_24);
if (x_62 == 0)
{
return x_24;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_24, 0);
x_64 = lean_ctor_get(x_24, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_24);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_66 = !lean_is_exclusive(x_12);
if (x_66 == 0)
{
return x_12;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_12, 0);
x_68 = lean_ctor_get(x_12, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_12);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("zeroExtend", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceZeroExtend___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceZeroExtend___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceZeroExtend___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceZeroExtend___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceZeroExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceZeroExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceZeroExtend", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceZeroExtend___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceZeroExtend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__7;
x_4 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3771_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3773_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
lean_inc(x_9);
lean_inc(x_8);
lean_inc(x_7);
lean_inc(x_6);
x_12 = l_BitVec_fromExpr_x3f(x_11, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_11);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
lean_object* x_20; lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; 
x_20 = lean_ctor_get(x_12, 1);
lean_inc(x_20);
lean_dec(x_12);
x_21 = lean_ctor_get(x_13, 0);
lean_inc(x_21);
lean_dec(x_13);
x_22 = l_Lean_Expr_appFn_x21(x_1);
x_23 = l_Lean_Expr_appArg_x21(x_22);
lean_dec(x_22);
x_24 = l_Lean_Meta_getNatValue_x3f(x_23, x_6, x_7, x_8, x_9, x_20);
if (lean_obj_tag(x_24) == 0)
{
lean_object* x_25; 
x_25 = lean_ctor_get(x_24, 0);
lean_inc(x_25);
if (lean_obj_tag(x_25) == 0)
{
uint8_t x_26; 
lean_dec(x_21);
x_26 = !lean_is_exclusive(x_24);
if (x_26 == 0)
{
lean_object* x_27; lean_object* x_28; 
x_27 = lean_ctor_get(x_24, 0);
lean_dec(x_27);
x_28 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_24, 0, x_28);
return x_24;
}
else
{
lean_object* x_29; lean_object* x_30; lean_object* x_31; 
x_29 = lean_ctor_get(x_24, 1);
lean_inc(x_29);
lean_dec(x_24);
x_30 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_31 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_31, 0, x_30);
lean_ctor_set(x_31, 1, x_29);
return x_31;
}
}
else
{
uint8_t x_32; 
x_32 = !lean_is_exclusive(x_24);
if (x_32 == 0)
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; lean_object* x_41; lean_object* x_42; uint32_t x_43; uint8_t x_44; lean_object* x_45; lean_object* x_46; 
x_33 = lean_ctor_get(x_24, 0);
lean_dec(x_33);
x_34 = lean_ctor_get(x_25, 0);
lean_inc(x_34);
lean_dec(x_25);
x_35 = lean_ctor_get(x_21, 0);
lean_inc(x_35);
x_36 = lean_ctor_get(x_21, 1);
lean_inc(x_36);
lean_dec(x_21);
x_37 = l_BitVec_signExtend(x_35, x_34, x_36);
lean_dec(x_35);
x_38 = l_Lean_mkNatLit(x_34);
x_39 = l_Lean_mkNatLit(x_37);
x_40 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_41 = l_Lean_mkAppB(x_40, x_38, x_39);
x_42 = lean_box(0);
x_43 = 0;
x_44 = 1;
x_45 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_45, 0, x_41);
lean_ctor_set(x_45, 1, x_42);
lean_ctor_set_uint32(x_45, sizeof(void*)*2, x_43);
lean_ctor_set_uint8(x_45, sizeof(void*)*2 + 4, x_44);
x_46 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_46, 0, x_45);
lean_ctor_set(x_24, 0, x_46);
return x_24;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; lean_object* x_50; lean_object* x_51; lean_object* x_52; lean_object* x_53; lean_object* x_54; lean_object* x_55; lean_object* x_56; uint32_t x_57; uint8_t x_58; lean_object* x_59; lean_object* x_60; lean_object* x_61; 
x_47 = lean_ctor_get(x_24, 1);
lean_inc(x_47);
lean_dec(x_24);
x_48 = lean_ctor_get(x_25, 0);
lean_inc(x_48);
lean_dec(x_25);
x_49 = lean_ctor_get(x_21, 0);
lean_inc(x_49);
x_50 = lean_ctor_get(x_21, 1);
lean_inc(x_50);
lean_dec(x_21);
x_51 = l_BitVec_signExtend(x_49, x_48, x_50);
lean_dec(x_49);
x_52 = l_Lean_mkNatLit(x_48);
x_53 = l_Lean_mkNatLit(x_51);
x_54 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_55 = l_Lean_mkAppB(x_54, x_52, x_53);
x_56 = lean_box(0);
x_57 = 0;
x_58 = 1;
x_59 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_59, 0, x_55);
lean_ctor_set(x_59, 1, x_56);
lean_ctor_set_uint32(x_59, sizeof(void*)*2, x_57);
lean_ctor_set_uint8(x_59, sizeof(void*)*2 + 4, x_58);
x_60 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_60, 0, x_59);
x_61 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_61, 0, x_60);
lean_ctor_set(x_61, 1, x_47);
return x_61;
}
}
}
else
{
uint8_t x_62; 
lean_dec(x_21);
x_62 = !lean_is_exclusive(x_24);
if (x_62 == 0)
{
return x_24;
}
else
{
lean_object* x_63; lean_object* x_64; lean_object* x_65; 
x_63 = lean_ctor_get(x_24, 0);
x_64 = lean_ctor_get(x_24, 1);
lean_inc(x_64);
lean_inc(x_63);
lean_dec(x_24);
x_65 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_65, 0, x_63);
lean_ctor_set(x_65, 1, x_64);
return x_65;
}
}
}
}
else
{
uint8_t x_66; 
lean_dec(x_9);
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_1);
x_66 = !lean_is_exclusive(x_12);
if (x_66 == 0)
{
return x_12;
}
else
{
lean_object* x_67; lean_object* x_68; lean_object* x_69; 
x_67 = lean_ctor_get(x_12, 0);
x_68 = lean_ctor_get(x_12, 1);
lean_inc(x_68);
lean_inc(x_67);
lean_dec(x_12);
x_69 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_69, 0, x_67);
lean_ctor_set(x_69, 1, x_68);
return x_69;
}
}
}
}
static lean_object* _init_l_BitVec_reduceSignExtend___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("signExtend", 10);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceSignExtend___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceSignExtend___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceSignExtend___closed__2;
x_11 = lean_unsigned_to_nat(3u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceSignExtend___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceSignExtend___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceSignExtend___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_11;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceSignExtend", 16);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceSignExtend___closed__2;
x_2 = lean_unsigned_to_nat(3u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4;
x_2 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__4;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__7() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__6;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceSignExtend), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2;
x_3 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__7;
x_4 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3792_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3794_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; lean_object* x_12; 
x_11 = l_Lean_Expr_appArg_x21(x_1);
x_12 = l_Lean_Meta_getNatValue_x3f(x_11, x_6, x_7, x_8, x_9, x_10);
if (lean_obj_tag(x_12) == 0)
{
lean_object* x_13; 
x_13 = lean_ctor_get(x_12, 0);
lean_inc(x_13);
if (lean_obj_tag(x_13) == 0)
{
uint8_t x_14; 
x_14 = !lean_is_exclusive(x_12);
if (x_14 == 0)
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_ctor_get(x_12, 0);
lean_dec(x_15);
x_16 = l_BitVec_reduceUnary___lambda__1___closed__1;
lean_ctor_set(x_12, 0, x_16);
return x_12;
}
else
{
lean_object* x_17; lean_object* x_18; lean_object* x_19; 
x_17 = lean_ctor_get(x_12, 1);
lean_inc(x_17);
lean_dec(x_12);
x_18 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_19 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_19, 0, x_18);
lean_ctor_set(x_19, 1, x_17);
return x_19;
}
}
else
{
uint8_t x_20; 
x_20 = !lean_is_exclusive(x_12);
if (x_20 == 0)
{
lean_object* x_21; lean_object* x_22; lean_object* x_23; lean_object* x_24; lean_object* x_25; lean_object* x_26; lean_object* x_27; lean_object* x_28; uint32_t x_29; uint8_t x_30; lean_object* x_31; lean_object* x_32; 
x_21 = lean_ctor_get(x_12, 0);
lean_dec(x_21);
x_22 = lean_ctor_get(x_13, 0);
lean_inc(x_22);
lean_dec(x_13);
x_23 = l_BitVec_allOnes(x_22);
x_24 = l_Lean_mkNatLit(x_22);
x_25 = l_Lean_mkNatLit(x_23);
x_26 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_27 = l_Lean_mkAppB(x_26, x_24, x_25);
x_28 = lean_box(0);
x_29 = 0;
x_30 = 1;
x_31 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_31, 0, x_27);
lean_ctor_set(x_31, 1, x_28);
lean_ctor_set_uint32(x_31, sizeof(void*)*2, x_29);
lean_ctor_set_uint8(x_31, sizeof(void*)*2 + 4, x_30);
x_32 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_32, 0, x_31);
lean_ctor_set(x_12, 0, x_32);
return x_12;
}
else
{
lean_object* x_33; lean_object* x_34; lean_object* x_35; lean_object* x_36; lean_object* x_37; lean_object* x_38; lean_object* x_39; lean_object* x_40; uint32_t x_41; uint8_t x_42; lean_object* x_43; lean_object* x_44; lean_object* x_45; 
x_33 = lean_ctor_get(x_12, 1);
lean_inc(x_33);
lean_dec(x_12);
x_34 = lean_ctor_get(x_13, 0);
lean_inc(x_34);
lean_dec(x_13);
x_35 = l_BitVec_allOnes(x_34);
x_36 = l_Lean_mkNatLit(x_34);
x_37 = l_Lean_mkNatLit(x_35);
x_38 = l_BitVec_reduceUnary___lambda__1___closed__5;
x_39 = l_Lean_mkAppB(x_38, x_36, x_37);
x_40 = lean_box(0);
x_41 = 0;
x_42 = 1;
x_43 = lean_alloc_ctor(0, 2, 5);
lean_ctor_set(x_43, 0, x_39);
lean_ctor_set(x_43, 1, x_40);
lean_ctor_set_uint32(x_43, sizeof(void*)*2, x_41);
lean_ctor_set_uint8(x_43, sizeof(void*)*2 + 4, x_42);
x_44 = lean_alloc_ctor(0, 1, 0);
lean_ctor_set(x_44, 0, x_43);
x_45 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_45, 0, x_44);
lean_ctor_set(x_45, 1, x_33);
return x_45;
}
}
}
else
{
uint8_t x_46; 
x_46 = !lean_is_exclusive(x_12);
if (x_46 == 0)
{
return x_12;
}
else
{
lean_object* x_47; lean_object* x_48; lean_object* x_49; 
x_47 = lean_ctor_get(x_12, 0);
x_48 = lean_ctor_get(x_12, 1);
lean_inc(x_48);
lean_inc(x_47);
lean_dec(x_12);
x_49 = lean_alloc_ctor(1, 2, 0);
lean_ctor_set(x_49, 0, x_47);
lean_ctor_set(x_49, 1, x_48);
return x_49;
}
}
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("allOnes", 7);
return x_1;
}
}
static lean_object* _init_l_BitVec_reduceAllOnes___closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l_BitVec_reduceAllOnes___closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; lean_object* x_11; uint8_t x_12; 
x_10 = l_BitVec_reduceAllOnes___closed__2;
x_11 = lean_unsigned_to_nat(1u);
x_12 = l_Lean_Expr_isAppOfArity(x_1, x_10, x_11);
if (x_12 == 0)
{
lean_object* x_13; lean_object* x_14; 
lean_dec(x_8);
lean_dec(x_7);
lean_dec(x_6);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
x_13 = l_BitVec_reduceUnary___lambda__1___closed__1;
x_14 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_14, 0, x_13);
lean_ctor_set(x_14, 1, x_9);
return x_14;
}
else
{
lean_object* x_15; lean_object* x_16; 
x_15 = lean_box(0);
x_16 = l_BitVec_reduceAllOnes___lambda__1(x_1, x_15, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
return x_16;
}
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___lambda__1___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9, lean_object* x_10) {
_start:
{
lean_object* x_11; 
x_11 = l_BitVec_reduceAllOnes___lambda__1(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10);
lean_dec(x_5);
lean_dec(x_4);
lean_dec(x_3);
lean_dec(x_2);
lean_dec(x_1);
return x_11;
}
}
LEAN_EXPORT lean_object* l_BitVec_reduceAllOnes___boxed(lean_object* x_1, lean_object* x_2, lean_object* x_3, lean_object* x_4, lean_object* x_5, lean_object* x_6, lean_object* x_7, lean_object* x_8, lean_object* x_9) {
_start:
{
lean_object* x_10; 
x_10 = l_BitVec_reduceAllOnes(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9);
lean_dec(x_1);
return x_10;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__1() {
_start:
{
lean_object* x_1; 
x_1 = lean_mk_string_from_bytes("reduceAllOnes", 13);
return x_1;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceUnary___lambda__1___closed__2;
x_2 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__1;
x_3 = l_Lean_Name_mkStr2(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__3() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l_BitVec_reduceAllOnes___closed__2;
x_2 = lean_unsigned_to_nat(1u);
x_3 = lean_alloc_ctor(0, 2, 0);
lean_ctor_set(x_3, 0, x_1);
lean_ctor_set(x_3, 1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__4() {
_start:
{
lean_object* x_1; lean_object* x_2; 
x_1 = lean_unsigned_to_nat(2u);
x_2 = lean_mk_empty_array_with_capacity(x_1);
return x_2;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__5() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__4;
x_2 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__3;
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__6() {
_start:
{
lean_object* x_1; lean_object* x_2; lean_object* x_3; 
x_1 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__5;
x_2 = lean_box(3);
x_3 = lean_array_push(x_1, x_2);
return x_3;
}
}
static lean_object* _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7() {
_start:
{
lean_object* x_1; 
x_1 = lean_alloc_closure((void*)(l_BitVec_reduceAllOnes___boxed), 9, 0);
return x_1;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; lean_object* x_4; lean_object* x_5; 
x_2 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2;
x_3 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__6;
x_4 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7;
x_5 = l_Lean_Meta_Simp_registerBuiltinSimproc(x_2, x_3, x_4, x_1);
return x_5;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3903_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
LEAN_EXPORT lean_object* l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3905_(lean_object* x_1) {
_start:
{
lean_object* x_2; lean_object* x_3; uint8_t x_4; lean_object* x_5; lean_object* x_6; 
x_2 = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1;
x_3 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2;
x_4 = 1;
x_5 = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7;
x_6 = l_Lean_Meta_Simp_addSimprocBuiltinAttrCore(x_2, x_3, x_4, x_5, x_1);
return x_6;
}
}
lean_object* initialize_Lean_Meta_LitValues(uint8_t builtin, lean_object*);
lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Nat(uint8_t builtin, lean_object*);
lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Int(uint8_t builtin, lean_object*);
lean_object* initialize_Init_Data_BitVec_Basic(uint8_t builtin, lean_object*);
static bool _G_initialized = false;
LEAN_EXPORT lean_object* initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec(uint8_t builtin, lean_object* w) {
lean_object * res;
if (_G_initialized) return lean_io_result_mk_ok(lean_box(0));
_G_initialized = true;
res = initialize_Lean_Meta_LitValues(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Nat(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Lean_Meta_Tactic_Simp_BuiltinSimprocs_Int(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
res = initialize_Init_Data_BitVec_Basic(builtin, lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
l_BitVec_reduceUnary___lambda__1___closed__1 = _init_l_BitVec_reduceUnary___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__1);
l_BitVec_reduceUnary___lambda__1___closed__2 = _init_l_BitVec_reduceUnary___lambda__1___closed__2();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__2);
l_BitVec_reduceUnary___lambda__1___closed__3 = _init_l_BitVec_reduceUnary___lambda__1___closed__3();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__3);
l_BitVec_reduceUnary___lambda__1___closed__4 = _init_l_BitVec_reduceUnary___lambda__1___closed__4();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__4);
l_BitVec_reduceUnary___lambda__1___closed__5 = _init_l_BitVec_reduceUnary___lambda__1___closed__5();
lean_mark_persistent(l_BitVec_reduceUnary___lambda__1___closed__5);
l_BitVec_reduceBin___lambda__2___closed__1 = _init_l_BitVec_reduceBin___lambda__2___closed__1();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__1);
l_BitVec_reduceBin___lambda__2___closed__2 = _init_l_BitVec_reduceBin___lambda__2___closed__2();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__2);
l_BitVec_reduceBin___lambda__2___closed__3 = _init_l_BitVec_reduceBin___lambda__2___closed__3();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__3);
l_BitVec_reduceBin___lambda__2___closed__4 = _init_l_BitVec_reduceBin___lambda__2___closed__4();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__4);
l_BitVec_reduceBin___lambda__2___closed__5 = _init_l_BitVec_reduceBin___lambda__2___closed__5();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__5);
l_BitVec_reduceBin___lambda__2___closed__6 = _init_l_BitVec_reduceBin___lambda__2___closed__6();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__6);
l_BitVec_reduceBin___lambda__2___closed__7 = _init_l_BitVec_reduceBin___lambda__2___closed__7();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__7);
l_BitVec_reduceBin___lambda__2___closed__8 = _init_l_BitVec_reduceBin___lambda__2___closed__8();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__8);
l_BitVec_reduceBin___lambda__2___closed__9 = _init_l_BitVec_reduceBin___lambda__2___closed__9();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__9);
l_BitVec_reduceBin___lambda__2___closed__10 = _init_l_BitVec_reduceBin___lambda__2___closed__10();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__10);
l_BitVec_reduceBin___lambda__2___closed__11 = _init_l_BitVec_reduceBin___lambda__2___closed__11();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__11);
l_BitVec_reduceBin___lambda__2___closed__12 = _init_l_BitVec_reduceBin___lambda__2___closed__12();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__12);
l_BitVec_reduceBin___lambda__2___closed__13 = _init_l_BitVec_reduceBin___lambda__2___closed__13();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__13);
l_BitVec_reduceBin___lambda__2___closed__14 = _init_l_BitVec_reduceBin___lambda__2___closed__14();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__14);
l_BitVec_reduceBin___lambda__2___closed__15 = _init_l_BitVec_reduceBin___lambda__2___closed__15();
lean_mark_persistent(l_BitVec_reduceBin___lambda__2___closed__15);
l_BitVec_reduceGetBit___lambda__1___closed__1 = _init_l_BitVec_reduceGetBit___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__1);
l_BitVec_reduceGetBit___lambda__1___closed__2 = _init_l_BitVec_reduceGetBit___lambda__1___closed__2();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__2);
l_BitVec_reduceGetBit___lambda__1___closed__3 = _init_l_BitVec_reduceGetBit___lambda__1___closed__3();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__3);
l_BitVec_reduceGetBit___lambda__1___closed__4 = _init_l_BitVec_reduceGetBit___lambda__1___closed__4();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__4);
l_BitVec_reduceGetBit___lambda__1___closed__5 = _init_l_BitVec_reduceGetBit___lambda__1___closed__5();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__5);
l_BitVec_reduceGetBit___lambda__1___closed__6 = _init_l_BitVec_reduceGetBit___lambda__1___closed__6();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__6);
l_BitVec_reduceGetBit___lambda__1___closed__7 = _init_l_BitVec_reduceGetBit___lambda__1___closed__7();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__7);
l_BitVec_reduceGetBit___lambda__1___closed__8 = _init_l_BitVec_reduceGetBit___lambda__1___closed__8();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__8);
l_BitVec_reduceGetBit___lambda__1___closed__9 = _init_l_BitVec_reduceGetBit___lambda__1___closed__9();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__9);
l_BitVec_reduceGetBit___lambda__1___closed__10 = _init_l_BitVec_reduceGetBit___lambda__1___closed__10();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__10);
l_BitVec_reduceGetBit___lambda__1___closed__11 = _init_l_BitVec_reduceGetBit___lambda__1___closed__11();
lean_mark_persistent(l_BitVec_reduceGetBit___lambda__1___closed__11);
l_BitVec_reduceNeg___closed__1 = _init_l_BitVec_reduceNeg___closed__1();
lean_mark_persistent(l_BitVec_reduceNeg___closed__1);
l_BitVec_reduceNeg___closed__2 = _init_l_BitVec_reduceNeg___closed__2();
lean_mark_persistent(l_BitVec_reduceNeg___closed__2);
l_BitVec_reduceNeg___closed__3 = _init_l_BitVec_reduceNeg___closed__3();
lean_mark_persistent(l_BitVec_reduceNeg___closed__3);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__1 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__1);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__2);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__3 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__3);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__4 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__4);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__5);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__6);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__7 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__7);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__8 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__8);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__9 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__9);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__10 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__10);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__11 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__11);
l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148____closed__12);
if (builtin) {res = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1148_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1150_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1 = _init_l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152____closed__1);
if (builtin) {res = l___regBuiltin_BitVec_reduceNeg_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1152_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceNot___closed__1 = _init_l_BitVec_reduceNot___closed__1();
lean_mark_persistent(l_BitVec_reduceNot___closed__1);
l_BitVec_reduceNot___closed__2 = _init_l_BitVec_reduceNot___closed__2();
lean_mark_persistent(l_BitVec_reduceNot___closed__2);
l_BitVec_reduceNot___closed__3 = _init_l_BitVec_reduceNot___closed__3();
lean_mark_persistent(l_BitVec_reduceNot___closed__3);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__1 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__1);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__2);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__3 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__3);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__4 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__4);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__5 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__5);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__6 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__6);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__7 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__7);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__8 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__8);
l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9 = _init_l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1185_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1187_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceNot_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1189_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAbs___closed__1 = _init_l_BitVec_reduceAbs___closed__1();
lean_mark_persistent(l_BitVec_reduceAbs___closed__1);
l_BitVec_reduceAbs___closed__2 = _init_l_BitVec_reduceAbs___closed__2();
lean_mark_persistent(l_BitVec_reduceAbs___closed__2);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__1 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__1);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__2);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__3 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__3);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__4);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__5 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__5);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__6 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__6);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__7 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__7);
l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8 = _init_l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1206_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1208_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAbs_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1210_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAnd___closed__1 = _init_l_BitVec_reduceAnd___closed__1();
lean_mark_persistent(l_BitVec_reduceAnd___closed__1);
l_BitVec_reduceAnd___closed__2 = _init_l_BitVec_reduceAnd___closed__2();
lean_mark_persistent(l_BitVec_reduceAnd___closed__2);
l_BitVec_reduceAnd___closed__3 = _init_l_BitVec_reduceAnd___closed__3();
lean_mark_persistent(l_BitVec_reduceAnd___closed__3);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__1 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__1);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__2);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__3 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__3);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__4);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__5 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__5);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__6 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__6);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__7 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__7);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__8 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__8);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__9 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__9);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__10 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__10);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__11 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__11);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__12 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__12);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__13 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__13);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__14 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__14);
l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15 = _init_l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248____closed__15);
if (builtin) {res = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1248_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1250_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAnd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1252_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOr___closed__1 = _init_l_BitVec_reduceOr___closed__1();
lean_mark_persistent(l_BitVec_reduceOr___closed__1);
l_BitVec_reduceOr___closed__2 = _init_l_BitVec_reduceOr___closed__2();
lean_mark_persistent(l_BitVec_reduceOr___closed__2);
l_BitVec_reduceOr___closed__3 = _init_l_BitVec_reduceOr___closed__3();
lean_mark_persistent(l_BitVec_reduceOr___closed__3);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__1 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__1);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__2);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__3 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__3);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__4 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__4);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__5 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__5);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__6 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__6);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__7 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__7);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__8 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__8);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__9 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__9);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__10 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__10);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__11 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__11);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__12 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__12);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__13 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__13);
l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14 = _init_l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1290_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1292_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1294_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceXOr___closed__1 = _init_l_BitVec_reduceXOr___closed__1();
lean_mark_persistent(l_BitVec_reduceXOr___closed__1);
l_BitVec_reduceXOr___closed__2 = _init_l_BitVec_reduceXOr___closed__2();
lean_mark_persistent(l_BitVec_reduceXOr___closed__2);
l_BitVec_reduceXOr___closed__3 = _init_l_BitVec_reduceXOr___closed__3();
lean_mark_persistent(l_BitVec_reduceXOr___closed__3);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__1 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__1);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__2);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__3 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__3);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__4 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__4);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__5 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__5);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__6 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__6);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__7 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__7);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__8 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__8);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__9 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__9);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__10 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__10);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__11 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__11);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__12 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__12);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__13 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__13);
l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14 = _init_l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1332_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1334_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceXOr_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1336_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAdd___closed__1 = _init_l_BitVec_reduceAdd___closed__1();
lean_mark_persistent(l_BitVec_reduceAdd___closed__1);
l_BitVec_reduceAdd___closed__2 = _init_l_BitVec_reduceAdd___closed__2();
lean_mark_persistent(l_BitVec_reduceAdd___closed__2);
l_BitVec_reduceAdd___closed__3 = _init_l_BitVec_reduceAdd___closed__3();
lean_mark_persistent(l_BitVec_reduceAdd___closed__3);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__1 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__1);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__2);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__3 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__3);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__4 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__4);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__5 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__5);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__6 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__6);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__7 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__7);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__8 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__8);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__9 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__9);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__10 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__10);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__11 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__11);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__12 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__12);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__13 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__13);
l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14 = _init_l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1374_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1376_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAdd_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1378_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMul___closed__1 = _init_l_BitVec_reduceMul___closed__1();
lean_mark_persistent(l_BitVec_reduceMul___closed__1);
l_BitVec_reduceMul___closed__2 = _init_l_BitVec_reduceMul___closed__2();
lean_mark_persistent(l_BitVec_reduceMul___closed__2);
l_BitVec_reduceMul___closed__3 = _init_l_BitVec_reduceMul___closed__3();
lean_mark_persistent(l_BitVec_reduceMul___closed__3);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__1 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__1);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__2);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__3 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__3);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__4 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__4);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__5 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__5);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__6 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__6);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__7 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__7);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__8 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__8);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__9 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__9);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__10 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__10);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__11 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__11);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__12 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__12);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__13 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__13);
l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14 = _init_l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1416_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1418_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceMul_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1420_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSub___closed__1 = _init_l_BitVec_reduceSub___closed__1();
lean_mark_persistent(l_BitVec_reduceSub___closed__1);
l_BitVec_reduceSub___closed__2 = _init_l_BitVec_reduceSub___closed__2();
lean_mark_persistent(l_BitVec_reduceSub___closed__2);
l_BitVec_reduceSub___closed__3 = _init_l_BitVec_reduceSub___closed__3();
lean_mark_persistent(l_BitVec_reduceSub___closed__3);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__1 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__1);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__2);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__3 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__3);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__4 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__4);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__5 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__5);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__6 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__6);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__7 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__7);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__8 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__8);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__9 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__9);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__10 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__10);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__11 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__11);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__12 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__12);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__13 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__13);
l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14 = _init_l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1458_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1460_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSub_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1462_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceDiv___closed__1 = _init_l_BitVec_reduceDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceDiv___closed__1);
l_BitVec_reduceDiv___closed__2 = _init_l_BitVec_reduceDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceDiv___closed__2);
l_BitVec_reduceDiv___closed__3 = _init_l_BitVec_reduceDiv___closed__3();
lean_mark_persistent(l_BitVec_reduceDiv___closed__3);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__1 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__1);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__2);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__3 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__3);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__4 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__4);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__5 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__5);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__6 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__6);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__7 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__7);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__8 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__8);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__9 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__9);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__10 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__10);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__11 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__11);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__12 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__12);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__13 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__13);
l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14 = _init_l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1500_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1502_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1504_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceMod___closed__1 = _init_l_BitVec_reduceMod___closed__1();
lean_mark_persistent(l_BitVec_reduceMod___closed__1);
l_BitVec_reduceMod___closed__2 = _init_l_BitVec_reduceMod___closed__2();
lean_mark_persistent(l_BitVec_reduceMod___closed__2);
l_BitVec_reduceMod___closed__3 = _init_l_BitVec_reduceMod___closed__3();
lean_mark_persistent(l_BitVec_reduceMod___closed__3);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__1 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__1);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__2);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__3 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__3);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__4 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__4);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__5 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__5);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__6 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__6);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__7 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__7);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__8 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__8);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__9 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__9);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__10 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__10);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__11 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__11);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__12 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__12);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__13 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__13);
l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14 = _init_l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14();
lean_mark_persistent(l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542____closed__14);
if (builtin) {res = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1542_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1544_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1546_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUMod___closed__1 = _init_l_BitVec_reduceUMod___closed__1();
lean_mark_persistent(l_BitVec_reduceUMod___closed__1);
l_BitVec_reduceUMod___closed__2 = _init_l_BitVec_reduceUMod___closed__2();
lean_mark_persistent(l_BitVec_reduceUMod___closed__2);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__1 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__1);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__2);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__3 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__3);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__4);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__5 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__5);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__6 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__6);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__7 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__7);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__8 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__8);
l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9 = _init_l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1568_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1570_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1572_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUDiv___closed__1 = _init_l_BitVec_reduceUDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceUDiv___closed__1);
l_BitVec_reduceUDiv___closed__2 = _init_l_BitVec_reduceUDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceUDiv___closed__2);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__1 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__1);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__2);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__3 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__3);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__4 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__4);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__5 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__5);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__6 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__6);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__7 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__7);
l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8 = _init_l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1594_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1596_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1598_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTUDiv___closed__1 = _init_l_BitVec_reduceSMTUDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceSMTUDiv___closed__1);
l_BitVec_reduceSMTUDiv___closed__2 = _init_l_BitVec_reduceSMTUDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceSMTUDiv___closed__2);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__1 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__1);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__2);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__3 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__3);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__4 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__4);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__5 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__5);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__6 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__6);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__7 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__7);
l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8 = _init_l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1620_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1622_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMTUDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1624_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMod___closed__1 = _init_l_BitVec_reduceSMod___closed__1();
lean_mark_persistent(l_BitVec_reduceSMod___closed__1);
l_BitVec_reduceSMod___closed__2 = _init_l_BitVec_reduceSMod___closed__2();
lean_mark_persistent(l_BitVec_reduceSMod___closed__2);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__1 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__1);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__2);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__3 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__3);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__4 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__4);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__5 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__5);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__6 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__6);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__7 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__7);
l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8 = _init_l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1646_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1648_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMod_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1650_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSRem___closed__1 = _init_l_BitVec_reduceSRem___closed__1();
lean_mark_persistent(l_BitVec_reduceSRem___closed__1);
l_BitVec_reduceSRem___closed__2 = _init_l_BitVec_reduceSRem___closed__2();
lean_mark_persistent(l_BitVec_reduceSRem___closed__2);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__1 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__1);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__2);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__3 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__3);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__4 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__4);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__5 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__5);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__6 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__6);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__7 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__7);
l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8 = _init_l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1672_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1674_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSRem_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1676_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSDiv___closed__1 = _init_l_BitVec_reduceSDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceSDiv___closed__1);
l_BitVec_reduceSDiv___closed__2 = _init_l_BitVec_reduceSDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceSDiv___closed__2);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__1 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__1);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__2);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__3 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__3);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__4 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__4);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__5 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__5);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__6 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__6);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__7 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__7);
l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8 = _init_l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1698_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1700_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1702_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSMTSDiv___closed__1 = _init_l_BitVec_reduceSMTSDiv___closed__1();
lean_mark_persistent(l_BitVec_reduceSMTSDiv___closed__1);
l_BitVec_reduceSMTSDiv___closed__2 = _init_l_BitVec_reduceSMTSDiv___closed__2();
lean_mark_persistent(l_BitVec_reduceSMTSDiv___closed__2);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__1 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__1);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__2);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__3 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__3);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__4 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__4);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__5 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__5);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__6 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__6);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__7 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__7);
l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8 = _init_l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1724_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1726_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSMTSDiv_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1728_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetLsb___closed__1 = _init_l_BitVec_reduceGetLsb___closed__1();
lean_mark_persistent(l_BitVec_reduceGetLsb___closed__1);
l_BitVec_reduceGetLsb___closed__2 = _init_l_BitVec_reduceGetLsb___closed__2();
lean_mark_persistent(l_BitVec_reduceGetLsb___closed__2);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__1 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__1);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__2);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__3 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__3);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__4 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__4);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__5 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__5);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__6 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__6);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__7 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__7);
l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8 = _init_l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1745_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1747_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGetLsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1749_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGetMsb___closed__1 = _init_l_BitVec_reduceGetMsb___closed__1();
lean_mark_persistent(l_BitVec_reduceGetMsb___closed__1);
l_BitVec_reduceGetMsb___closed__2 = _init_l_BitVec_reduceGetMsb___closed__2();
lean_mark_persistent(l_BitVec_reduceGetMsb___closed__2);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__1 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__1);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__2);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__3 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__3);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__4 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__4);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__5 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__5);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__6 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__6);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__7 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__7);
l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8 = _init_l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1766_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1768_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGetMsb_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1770_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeft___closed__1 = _init_l_BitVec_reduceShiftLeft___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftLeft___closed__1);
l_BitVec_reduceShiftLeft___closed__2 = _init_l_BitVec_reduceShiftLeft___closed__2();
lean_mark_persistent(l_BitVec_reduceShiftLeft___closed__2);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__1 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__1);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__2);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__3 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__3);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__4 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__4);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__5 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__5);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__6 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__6);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__7 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__7);
l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8 = _init_l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1788_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1790_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1792_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceUShiftRight___closed__1 = _init_l_BitVec_reduceUShiftRight___closed__1();
lean_mark_persistent(l_BitVec_reduceUShiftRight___closed__1);
l_BitVec_reduceUShiftRight___closed__2 = _init_l_BitVec_reduceUShiftRight___closed__2();
lean_mark_persistent(l_BitVec_reduceUShiftRight___closed__2);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__1 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__1);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__2);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__3 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__3);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__4 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__4);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__5 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__5);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__6 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__6);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__7 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__7);
l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8 = _init_l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1810_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1812_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceUShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1814_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSShiftRight___closed__1 = _init_l_BitVec_reduceSShiftRight___closed__1();
lean_mark_persistent(l_BitVec_reduceSShiftRight___closed__1);
l_BitVec_reduceSShiftRight___closed__2 = _init_l_BitVec_reduceSShiftRight___closed__2();
lean_mark_persistent(l_BitVec_reduceSShiftRight___closed__2);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__1 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__1);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__2);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__3 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__3);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__4 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__4);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__5 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__5);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__6 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__6);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__7 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__7);
l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8 = _init_l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1832_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1834_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1836_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftLeft___closed__1 = _init_l_BitVec_reduceHShiftLeft___closed__1();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___closed__1);
l_BitVec_reduceHShiftLeft___closed__2 = _init_l_BitVec_reduceHShiftLeft___closed__2();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___closed__2);
l_BitVec_reduceHShiftLeft___closed__3 = _init_l_BitVec_reduceHShiftLeft___closed__3();
lean_mark_persistent(l_BitVec_reduceHShiftLeft___closed__3);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__1 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__1);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__2);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__3 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__3);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__4);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__5 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__5);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__6 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__6);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__7 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__7);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__8 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__8);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__9 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__9);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__10 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__10);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__11 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__11);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__12 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__12);
l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13 = _init_l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874____closed__13);
if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1874_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1876_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1878_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceHShiftRight___closed__1 = _init_l_BitVec_reduceHShiftRight___closed__1();
lean_mark_persistent(l_BitVec_reduceHShiftRight___closed__1);
l_BitVec_reduceHShiftRight___closed__2 = _init_l_BitVec_reduceHShiftRight___closed__2();
lean_mark_persistent(l_BitVec_reduceHShiftRight___closed__2);
l_BitVec_reduceHShiftRight___closed__3 = _init_l_BitVec_reduceHShiftRight___closed__3();
lean_mark_persistent(l_BitVec_reduceHShiftRight___closed__3);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__1 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__1);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__2);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__3 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__3);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__4 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__4);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__5 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__5);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__6 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__6);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__7 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__7);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__8 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__8);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__9 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__9);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__10 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__10);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__11 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__11);
l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12 = _init_l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916____closed__12);
if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1916_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1918_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceHShiftRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1920_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateLeft___closed__1 = _init_l_BitVec_reduceRotateLeft___closed__1();
lean_mark_persistent(l_BitVec_reduceRotateLeft___closed__1);
l_BitVec_reduceRotateLeft___closed__2 = _init_l_BitVec_reduceRotateLeft___closed__2();
lean_mark_persistent(l_BitVec_reduceRotateLeft___closed__2);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__1 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__1);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__2);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__3 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__3);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__4 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__4);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__5 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__5);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__6 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__6);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__7 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__7);
l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8 = _init_l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1938_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1940_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceRotateLeft_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1942_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceRotateRight___closed__1 = _init_l_BitVec_reduceRotateRight___closed__1();
lean_mark_persistent(l_BitVec_reduceRotateRight___closed__1);
l_BitVec_reduceRotateRight___closed__2 = _init_l_BitVec_reduceRotateRight___closed__2();
lean_mark_persistent(l_BitVec_reduceRotateRight___closed__2);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__1 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__1);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__2);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__3 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__3);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__4 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__4);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__5 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__5);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__6 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__6);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__7 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__7);
l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8 = _init_l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1960_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1962_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceRotateRight_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_1964_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAppend___closed__1 = _init_l_BitVec_reduceAppend___closed__1();
lean_mark_persistent(l_BitVec_reduceAppend___closed__1);
l_BitVec_reduceAppend___closed__2 = _init_l_BitVec_reduceAppend___closed__2();
lean_mark_persistent(l_BitVec_reduceAppend___closed__2);
l_BitVec_reduceAppend___closed__3 = _init_l_BitVec_reduceAppend___closed__3();
lean_mark_persistent(l_BitVec_reduceAppend___closed__3);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__1 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__1);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__2);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__3 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__3);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__4 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__4);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__5 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__5);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__6 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__6);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__7 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__7);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__8 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__8);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__9 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__9);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__10 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__10);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__11 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__11);
l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12 = _init_l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117____closed__12);
if (builtin) {res = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2117_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2119_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAppend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2121_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceCast___closed__1 = _init_l_BitVec_reduceCast___closed__1();
lean_mark_persistent(l_BitVec_reduceCast___closed__1);
l_BitVec_reduceCast___closed__2 = _init_l_BitVec_reduceCast___closed__2();
lean_mark_persistent(l_BitVec_reduceCast___closed__2);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__1 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__1);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__2);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__3 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__3);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__4 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__4);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__5 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__5);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__6 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__6);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__7 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__7);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__8 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__8);
l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9 = _init_l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2266_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2268_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceCast_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2270_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToNat___closed__1 = _init_l_BitVec_reduceToNat___closed__1();
lean_mark_persistent(l_BitVec_reduceToNat___closed__1);
l_BitVec_reduceToNat___closed__2 = _init_l_BitVec_reduceToNat___closed__2();
lean_mark_persistent(l_BitVec_reduceToNat___closed__2);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__1);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__2);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__3 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__3);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__4 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__4);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__5 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__5);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__6 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__6);
l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7 = _init_l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2374_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2376_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceToNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2378_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceToInt___lambda__1___closed__1 = _init_l_BitVec_reduceToInt___lambda__1___closed__1();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__1);
l_BitVec_reduceToInt___lambda__1___closed__2 = _init_l_BitVec_reduceToInt___lambda__1___closed__2();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__2);
l_BitVec_reduceToInt___lambda__1___closed__3 = _init_l_BitVec_reduceToInt___lambda__1___closed__3();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__3);
l_BitVec_reduceToInt___lambda__1___closed__4 = _init_l_BitVec_reduceToInt___lambda__1___closed__4();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__4);
l_BitVec_reduceToInt___lambda__1___closed__5 = _init_l_BitVec_reduceToInt___lambda__1___closed__5();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__5);
l_BitVec_reduceToInt___lambda__1___closed__6 = _init_l_BitVec_reduceToInt___lambda__1___closed__6();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__6);
l_BitVec_reduceToInt___lambda__1___closed__7 = _init_l_BitVec_reduceToInt___lambda__1___closed__7();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__7);
l_BitVec_reduceToInt___lambda__1___closed__8 = _init_l_BitVec_reduceToInt___lambda__1___closed__8();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__8);
l_BitVec_reduceToInt___lambda__1___closed__9 = _init_l_BitVec_reduceToInt___lambda__1___closed__9();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__9);
l_BitVec_reduceToInt___lambda__1___closed__10 = _init_l_BitVec_reduceToInt___lambda__1___closed__10();
lean_mark_persistent(l_BitVec_reduceToInt___lambda__1___closed__10);
l_BitVec_reduceToInt___closed__1 = _init_l_BitVec_reduceToInt___closed__1();
lean_mark_persistent(l_BitVec_reduceToInt___closed__1);
l_BitVec_reduceToInt___closed__2 = _init_l_BitVec_reduceToInt___closed__2();
lean_mark_persistent(l_BitVec_reduceToInt___closed__2);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__1 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__1);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__2);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__3 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__3);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__4 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__4);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__5 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__5);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__6 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__6);
l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7 = _init_l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2482_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2484_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceToInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2486_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceOfInt___closed__1 = _init_l_BitVec_reduceOfInt___closed__1();
lean_mark_persistent(l_BitVec_reduceOfInt___closed__1);
l_BitVec_reduceOfInt___closed__2 = _init_l_BitVec_reduceOfInt___closed__2();
lean_mark_persistent(l_BitVec_reduceOfInt___closed__2);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__1 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__1);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__2);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__3 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__3);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__4 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__4);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__5 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__5);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__6 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__6);
l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7 = _init_l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2631_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2633_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOfInt_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2635_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__1 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__1);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__2);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__3 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__3);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__4 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__4);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__5 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__5);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__6 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__6);
l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7 = _init_l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2829_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2831_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceOfNat_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2833_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLT___closed__1 = _init_l_BitVec_reduceLT___closed__1();
lean_mark_persistent(l_BitVec_reduceLT___closed__1);
l_BitVec_reduceLT___closed__2 = _init_l_BitVec_reduceLT___closed__2();
lean_mark_persistent(l_BitVec_reduceLT___closed__2);
l_BitVec_reduceLT___closed__3 = _init_l_BitVec_reduceLT___closed__3();
lean_mark_persistent(l_BitVec_reduceLT___closed__3);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__1 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__1);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__2);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__3 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__3);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__4 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__4);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__5 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__5);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__6 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__6);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__7 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__7);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__8 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__8);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__9 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__9);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__10 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__10);
l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11 = _init_l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872____closed__11);
if (builtin) {res = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2872_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2874_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2876_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceLE___closed__1 = _init_l_BitVec_reduceLE___closed__1();
lean_mark_persistent(l_BitVec_reduceLE___closed__1);
l_BitVec_reduceLE___closed__2 = _init_l_BitVec_reduceLE___closed__2();
lean_mark_persistent(l_BitVec_reduceLE___closed__2);
l_BitVec_reduceLE___closed__3 = _init_l_BitVec_reduceLE___closed__3();
lean_mark_persistent(l_BitVec_reduceLE___closed__3);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__1 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__1);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__2);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__3 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__3);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__4 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__4);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__5 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__5);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__6 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__6);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__7 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__7);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__8 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__8);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__9 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__9);
l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10 = _init_l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10();
lean_mark_persistent(l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915____closed__10);
if (builtin) {res = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2915_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2917_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2919_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGT___closed__1 = _init_l_BitVec_reduceGT___closed__1();
lean_mark_persistent(l_BitVec_reduceGT___closed__1);
l_BitVec_reduceGT___closed__2 = _init_l_BitVec_reduceGT___closed__2();
lean_mark_persistent(l_BitVec_reduceGT___closed__2);
l_BitVec_reduceGT___closed__3 = _init_l_BitVec_reduceGT___closed__3();
lean_mark_persistent(l_BitVec_reduceGT___closed__3);
l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__1 = _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__1);
l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2 = _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__2);
l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3 = _init_l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958____closed__3);
if (builtin) {res = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2958_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2960_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_2962_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceGE___closed__1 = _init_l_BitVec_reduceGE___closed__1();
lean_mark_persistent(l_BitVec_reduceGE___closed__1);
l_BitVec_reduceGE___closed__2 = _init_l_BitVec_reduceGE___closed__2();
lean_mark_persistent(l_BitVec_reduceGE___closed__2);
l_BitVec_reduceGE___closed__3 = _init_l_BitVec_reduceGE___closed__3();
lean_mark_persistent(l_BitVec_reduceGE___closed__3);
l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__1 = _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__1);
l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2 = _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__2);
l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3 = _init_l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001____closed__3);
if (builtin) {res = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3001_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3003_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceGE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3005_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULT___closed__1 = _init_l_BitVec_reduceULT___closed__1();
lean_mark_persistent(l_BitVec_reduceULT___closed__1);
l_BitVec_reduceULT___closed__2 = _init_l_BitVec_reduceULT___closed__2();
lean_mark_persistent(l_BitVec_reduceULT___closed__2);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__1 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__1);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__2);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__3 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__3);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__4 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__4);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__5 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__5);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__6 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__6);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__7 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__7);
l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8 = _init_l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3024_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3026_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceULT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3028_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceULE___closed__1 = _init_l_BitVec_reduceULE___closed__1();
lean_mark_persistent(l_BitVec_reduceULE___closed__1);
l_BitVec_reduceULE___closed__2 = _init_l_BitVec_reduceULE___closed__2();
lean_mark_persistent(l_BitVec_reduceULE___closed__2);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__1 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__1);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__2);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__3 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__3);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__4 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__4);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__5 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__5);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__6 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__6);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__7 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__7);
l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8 = _init_l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3047_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3049_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceULE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3051_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLT___closed__1 = _init_l_BitVec_reduceSLT___closed__1();
lean_mark_persistent(l_BitVec_reduceSLT___closed__1);
l_BitVec_reduceSLT___closed__2 = _init_l_BitVec_reduceSLT___closed__2();
lean_mark_persistent(l_BitVec_reduceSLT___closed__2);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__1 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__1);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__2);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__3 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__3);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__4 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__4);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__5 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__5);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__6 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__6);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__7 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__7);
l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8 = _init_l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3070_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3072_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSLT_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3074_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSLE___closed__1 = _init_l_BitVec_reduceSLE___closed__1();
lean_mark_persistent(l_BitVec_reduceSLE___closed__1);
l_BitVec_reduceSLE___closed__2 = _init_l_BitVec_reduceSLE___closed__2();
lean_mark_persistent(l_BitVec_reduceSLE___closed__2);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__1 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__1);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__2);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__3 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__3);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__4 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__4);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__5 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__5);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__6 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__6);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__7 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__7);
l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8 = _init_l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3093_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3095_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSLE_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3097_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceZeroExtend_x27___closed__1 = _init_l_BitVec_reduceZeroExtend_x27___closed__1();
lean_mark_persistent(l_BitVec_reduceZeroExtend_x27___closed__1);
l_BitVec_reduceZeroExtend_x27___closed__2 = _init_l_BitVec_reduceZeroExtend_x27___closed__2();
lean_mark_persistent(l_BitVec_reduceZeroExtend_x27___closed__2);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__1 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__1);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__2);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__3 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__3);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__4 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__4);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__5 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__5);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__6 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__6);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__7 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__7);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__8 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__8);
l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9 = _init_l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3266_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3268_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3270_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceShiftLeftZeroExtend___closed__1 = _init_l_BitVec_reduceShiftLeftZeroExtend___closed__1();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___closed__1);
l_BitVec_reduceShiftLeftZeroExtend___closed__2 = _init_l_BitVec_reduceShiftLeftZeroExtend___closed__2();
lean_mark_persistent(l_BitVec_reduceShiftLeftZeroExtend___closed__2);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__1 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__1);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__2);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__3 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__3);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__4 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__4);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__5 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__5);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__6 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__6);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__7 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__7);
l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8 = _init_l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3414_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3416_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceShiftLeftZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3418_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceExtracLsb_x27___closed__1 = _init_l_BitVec_reduceExtracLsb_x27___closed__1();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___closed__1);
l_BitVec_reduceExtracLsb_x27___closed__2 = _init_l_BitVec_reduceExtracLsb_x27___closed__2();
lean_mark_persistent(l_BitVec_reduceExtracLsb_x27___closed__2);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__1 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__1);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__2);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__3 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__3);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__4 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__4);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__5 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__5);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__6 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__6);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__7 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__7);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__8 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__8);
l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9 = _init_l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9();
lean_mark_persistent(l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600____closed__9);
if (builtin) {res = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3600_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3602_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceExtracLsb_x27_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3604_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceReplicate___closed__1 = _init_l_BitVec_reduceReplicate___closed__1();
lean_mark_persistent(l_BitVec_reduceReplicate___closed__1);
l_BitVec_reduceReplicate___closed__2 = _init_l_BitVec_reduceReplicate___closed__2();
lean_mark_persistent(l_BitVec_reduceReplicate___closed__2);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__1 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__1);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__2);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__3 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__3);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__4 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__4);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__5 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__5);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__6 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__6);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__7 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__7);
l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8 = _init_l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3748_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3750_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceReplicate_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3752_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceZeroExtend___closed__1 = _init_l_BitVec_reduceZeroExtend___closed__1();
lean_mark_persistent(l_BitVec_reduceZeroExtend___closed__1);
l_BitVec_reduceZeroExtend___closed__2 = _init_l_BitVec_reduceZeroExtend___closed__2();
lean_mark_persistent(l_BitVec_reduceZeroExtend___closed__2);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__1 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__1);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__2);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__3 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__3);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__4 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__4);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__5 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__5);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__6 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__6);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__7 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__7);
l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8 = _init_l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3769_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3771_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceZeroExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3773_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceSignExtend___closed__1 = _init_l_BitVec_reduceSignExtend___closed__1();
lean_mark_persistent(l_BitVec_reduceSignExtend___closed__1);
l_BitVec_reduceSignExtend___closed__2 = _init_l_BitVec_reduceSignExtend___closed__2();
lean_mark_persistent(l_BitVec_reduceSignExtend___closed__2);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__1 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__1);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__2);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__3 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__3);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__4 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__4);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__5 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__5);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__6 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__6);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__7 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__7);
l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8 = _init_l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8();
lean_mark_persistent(l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790____closed__8);
if (builtin) {res = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3790_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3792_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceSignExtend_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3794_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}l_BitVec_reduceAllOnes___closed__1 = _init_l_BitVec_reduceAllOnes___closed__1();
lean_mark_persistent(l_BitVec_reduceAllOnes___closed__1);
l_BitVec_reduceAllOnes___closed__2 = _init_l_BitVec_reduceAllOnes___closed__2();
lean_mark_persistent(l_BitVec_reduceAllOnes___closed__2);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__1 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__1();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__1);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__2);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__3 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__3();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__3);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__4 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__4();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__4);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__5 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__5();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__5);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__6 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__6();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__6);
l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7 = _init_l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7();
lean_mark_persistent(l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901____closed__7);
if (builtin) {res = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3901_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3903_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}if (builtin) {res = l___regBuiltin_BitVec_reduceAllOnes_declare____x40_Lean_Meta_Tactic_Simp_BuiltinSimprocs_BitVec___hyg_3905_(lean_io_mk_world());
if (lean_io_result_is_error(res)) return res;
lean_dec_ref(res);
}return lean_io_result_mk_ok(lean_box(0));
}
#ifdef __cplusplus
}
#endif
